# overlays/custom-url/kustomization.yaml

# 베이스 파일 지정
resources:
- ../../base

# 패치 적용
patches:
# Master 스펙의 args 필드를 덮어씁니다.
- patch: |-
    - op: replace
      path: /spec/pytorchReplicaSpecs/Master/template/spec/nodeSelector/karpenter.sh/nodepool
      value: gpu
    - op: replace
      path: /spec/pytorchReplicaSpecs/Master/template/spec/nodeSelector/node.kubernetes.io/instance-type
      value: p4d.24xlarge
    - op: replace
      path: /spec/pytorchReplicaSpecs/Master/template/spec/affinity/podAffinity/requiredDuringSchedulingIgnoredDuringExecution/topologyKey
      value: kubernetes.io/hostname
    - op: replace
      path: /spec/pytorchReplicaSpecs/Master/template/spec/containers/0/args/0
      value: |
        git clone https://github.com/gnosia93/training-on-eks /workspace/code
        cd /workspace/code/samples/fsdp
        echo "working directory: "$(pwd)
        pip install -r requirements.txt
        torchrun --nnodes 4 --nproc_per_node 1 t5-fsdp.py
  target:
    kind: PyTorchJob
    name: pytorch-dist-job

# Worker 스펙의 args 필드를 덮어씁니다.
- patch: |-
    - op: replace
      path: /spec/pytorchReplicaSpecs/Worker/template/spec/nodeSelector/karpenter.sh/nodepool
      value: gpu
    - op: replace
      path: /spec/pytorchReplicaSpecs/Worker/template/spec/nodeSelector/node.kubernetes.io/instance-type
      value: p4d.24xlarge
    - op: replace
      path: /spec/pytorchReplicaSpecs/Worker/template/spec/affinity/podAffinity/requiredDuringSchedulingIgnoredDuringExecution/topologyKey
      value: kubernetes.io/hostname
    - op: replace
      path: /spec/pytorchReplicaSpecs/Worker/template/spec/containers/0/args/0
      value: |
        git clone https://github.com/gnosia93/training-on-eks /workspace/code
        cd /workspace/code/samples/fsdp
        echo "working directory: "$(pwd)
        pip install -r requirements.txt
        torchrun --nnodes 4 --nproc_per_node 1 t5-fsdp.py
    - op: replace
      path: /spec/pytorchReplicaSpecs/Worker/replicas
      value: 3        
  target:
    kind: PyTorchJob
    name: pytorch-dist-job
