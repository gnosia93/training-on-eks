
## Llama 8B 훈련 메모리 계산 ##

### 1. 총 메모리 공식 ###
총 VRAM = 모델 가중치 + 그래디언트 + 옵티마이저 상태 + 활성화 값

### 2. 8B 모델 상세 계산 (FP16 기준) ###

* 모델 가중치: 
  * 학습을 위해 모델을 메모리에 올리는 단계입니다.
  * 80억 파라미터 x 2바이트 = 16GB

* 그래디언트: 
  * 역전파 시 각 파라미터의 기울기를 저장하고, 모델 가중치와 동일한 크기가 필요하다.
  * 80억 파라미터 x 2바이트 = 16GB 

* 옵티마이저 상태 (Adam 기준):
  * 가장 많은 메모리를 차지하는 부분으로, Adam 옵티마이저는 가중치의 복사본(FP32), Momentum, Variance를 저장해야 하므로 파라미터당 총 12~16바이트가 필요합니다
  * 80억 파라미터 x 12바이트 = 96GB

* 활성화 값 및 여유 공간: 약 12GB 이상 (배치 사이즈 및 시퀀스 길이에 따라 증가)
  * 활성화 값 (Activations)이란?
  순전파(Forward Pass) 과정에서 각 층(Layer)의 연산 결과물들을 임시로 저장해두는 메모리이다. 역전파(Backward Pass) 때 그래디언트(기울기)를 계산하려면 이 값들이 반드시 필요하기 때문에 버리지 못하고 메모리에 들고 있어야 한다. 
    * 영향을 주는 요소:
       * 배치 사이즈(Batch Size): 한 번에 학습시키는 문장 개수가 많을수록 선형적으로 증가한다.
       * 시퀀스 길이(Sequence Length): 문장이 길어질수록 제곱(Square)에 비례하여 증가한다. (Self-Attention 연산 때문).
       * 모델 구조: Hidden Size(모델의 폭)와 레이어 수가 많을수록 커진다.
       * 8B 모델 예시:
          * 시퀀스 길이 2048, 배치 사이즈 1로 설정 시 약 4~6GB 정도를 차지합니다.
          * 하지만 시퀀스 길이를 8192로 늘리면 이 값만 20GB 이상으로 치솟을 수 있습니다.
  * 여유 공간 및 기타 (Misc / Overhead)
  하드웨어와 소프트웨어가 구동되기 위해 기본적으로 점유하는 영역이다.
     * CUDA 커널 메모리: GPU가 연산을 수행하기 위해 드라이버와 라이브러리(cuDNN 등)를 로드하는 데 약 1~2GB를 기본적으로 사용.
     * 임시 버퍼 (Temporary Buffers): 연산 중 데이터를 복사하거나 통신(Multi-GPU 시 데이터 교환)을 위해 일시적으로 사용하는 공간.
     * 단편화 (Memory Fragmentation): 메모리를 할당하고 해제하는 과정에서 실제 사용량보다 더 많은 공간이 예약되어 있어 사용할 수 없게 되는 현상. 보통 전체의 5~10% 정도 여유가 있어야 안전.

### 최소 필요량: 약 140GB ##
### 권장 사양: 160GB 이상의 VRAM (A100 80GB 또는 H100 80GB 2개 이상 필요) ###










