
## Llama 8B 훈련 메모리 계산 ##

### 1. 총 메모리 공식 ###
총 VRAM = 모델 가중치 + 그래디언트 + 옵티마이저 상태 + 활성화 값

### 2. 8B 모델 상세 계산 (FP16 기준) ###
* 모델 가중치: 80억 파라미터 x 2바이트 = 16GB
* 그래디언트: 
  * 역전파 시 각 파라미터의 기울기를 저장하고, 모델 가중치와 동일한 크기가 필요하다.
  * 80억 파라미터 x 2바이트 = 16GB 
* 옵티마이저 상태 (Adam 기준):
  * 가장 많은 메모리를 차지하는 부분으로, Adam 옵티마이저는 가중치의 복사본(FP32), Momentum, Variance를 저장해야 하므로 파라미터당 총 12~16바이트가 필요합니다
  * 80억 파라미터 x 12바이트 = 96GB


* 활성화 값 및 여유 공간: 약 12GB 이상 (배치 사이즈 및 시퀀스 길이에 따라 증가)

#### 최소 필요량: 약 140GB ###
#### 권장 사양: 160GB 이상의 VRAM (A100 80GB 또는 H100 80GB 2개 이상 필요) ####

