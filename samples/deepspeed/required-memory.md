
## Llama 8B Full Fine-tuning 메모리 계산 요약 ##

### 총 메모리 공식: ###
총 VRAM = 모델 가중치 + 그래디언트 + 옵티마이저 상태 + 활성화 값


8B 모델 상세 계산 (FP16 기준):
모델 가중치: 80억 파라미터 x 2바이트 = 16GB
그래디언트: 80억 파라미터 x 2바이트 = 16GB
옵티마이저 상태 (Adam 기준): 80억 파라미터 x 12바이트 = 96GB
활성화 값 및 여유 공간: 약 12GB 이상 (배치 사이즈 및 시퀀스 길이에 따라 증가)
최종 합계:
최소 필요량: 약 140GB
