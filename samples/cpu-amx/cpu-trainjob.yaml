apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  name: llama-3-8b
spec:
  podTemplateOverrides:
    - targetJobs:
        - name: node                                                  # ClusterTrainingRuntime 에 있는 runtime job template
      metadata:
        annotations:
          karpenter.sh/do-not-disrupt: "true"                         # Karpenter의 노드 회수 방지
      spec:
        nodeSelector:
          node.kubernetes.io/instance-type: ${INSTANCE_TYPE}              

        containers:
          - name: node                                                # -name: node 은 상당히 중요한 설정값 / ClusterTrainingRuntime 에 있는 컨테이너 이름이 node 이다.
            volumeMounts:                                             # 이 값을 잘못 설정하는 경우 TrainJob 이 시작되지 않는다. 
              - mountPath: /dev/shm
                name: dshm
            
        volumes:
          - name: dshm
            emptyDir:
              medium: Memory
              sizeLimit: "2Gi"                
      
  runtimeRef:
    name: torch-distributed                   # torch 분산 백엔드 사용 

  trainer:
    numNodes: ${NODE_NUM}                     # 노드수 설정
    numProcPerNode: 1                      # 노드별 프로세스 갯수                                                                               
    image: public.ecr.aws/deep-learning-containers/pytorch-training:2.8.0-gpu-py312-cu129-ubuntu22.04-ec2-v1.0

    # 이전 설정: --nproc_per_node=1 (동적 설정을 위해 gpu 로 변경, 이 경우 서버에 할당된 모든 gpu 사용, limit 가 4 라도 8개 가진 서버라면 8 개 사용)
    command:
      - /bin/bash
      - -c
      - |
        git clone https://github.com/gnosia93/training-on-eks /workspace/code
        cd /workspace/code/samples/deepspeed
        huggingface-cli login --token "${HF_TOKEN}"
        echo "=== Launching Distributed Training ==="
        pip install -r requirements.txt && \
        echo "pip 설치 완료, 학습을 시작합니다..." && \
        echo "Master Address: ${PET_MASTER_ADDR}" && \
        echo "Master Port: ${PET_MASTER_PORT}" && \
        torchrun \
          --nproc_per_node=1 \
          --rdzv_id=llama-3-8b-job \
          --rdzv_backend=c10d \
          --rdzv_endpoint=${PET_MASTER_ADDR}:${PET_MASTER_PORT} \
          --rdzv_conf=timeout=1200 \
          llama-3-8b.py 
    resourcesPerNode:
      resourcesPerNode:
        requests:
          cpu: "32"
          memory: "64Gi"
        limits:
          cpu: "32"
          memory: "64Gi"                 
 
