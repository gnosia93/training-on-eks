## TP vs TP+SP ##

모델이 커지면 학습 과정에서 데이터를 저장하는 활성화 메모리(Activation Memory)가 그래픽 카드(GPU) 용량을 초과하는 병목 현상이 발생한다. 이를 해결하기 위해 텐서 병렬화(Tensor Parallel, TP)를 사용하지만, TP만으로는 부족한 부분을 시퀀스 병렬화(Sequence Parallel, SP)가 채워주게 된다. 

### 1. 왜 활성화 메모리가 병목인가요? ###
학습할 때 역전파(Backpropagation)를 위해 forward 단계의 중간값(활성화 값)을 메모리에 계속 들고 있어야 한다. 모델이 커지고 문장(Sequence)이 길어질수록 이 데이터 양이 기하급수적으로 늘어나 GPU 메모리를 다 잡아먹게 된다. 

### 2. 텐서 병렬화(TP)의 한계 ###
TP는 연산량이 많은 Attention이나 MLP 층의 행렬을 쪼개서 여러 GPU가 나눠 갖게 한다. 하지만 LayerNorm이나 RMSNorm 같은 층은 연산량은 적으면서도 전체 시퀀스 데이터를 그대로 복사해서 들고 있어야 하므로, 여기서 메모리 낭비가 발생한다. 

### 3. 시퀀스 병렬화(SP)의 역할 ###
SP는 바로 이 LayerNorm/RMSNorm 층에서 데이터를 시퀀스(문장 길이) 방향으로 쪼개서 각 GPU에 나눠 준다. 
* 기존 TP: 모든 GPU가 똑같은 전체 문장 데이터를 복사해서 들고 있음.
* SP 적용 시: 1번 GPU는 문장의 앞부분, 2번 GPU는 뒷부분만 들고 연산함.
* 결과: 각 GPU가 저장해야 할 활성화 메모리 양이 병렬화 개수만큼 줄어들어, 더 긴 문장이나 더 큰 모델을 학습할 수 있게 된다. 
요약하자면, "연산이 무거운 곳은 TP로, 연산은 가볍지만 메모리를 많이 먹는 Norm 층은 SP로 쪼개서" 전체적인 메모리 효율을 극대화하는 전략이다. 

## SP 의 장점 ##
시퀀스 병렬화(SP)를 도입하면 통신 방식이 All-Reduce 방식에서 Reduce-Scatter와 All-Gather의 조합으로 바뀐다. 핵심은 "통신량은 그대로인데, 메모리 효율은 극대화된다"는 점입이다. 

### 1. 통신 방식의 변화 (TP vs TP+SP) ###
기존의 텐서 병렬화(TP)만 사용할 때와 SP를 추가했을 때의 통신 과정을 비교하면 이해가 쉽다. 
* 기존 TP (All-Reduce 사용):연산이 끝나면 각 GPU가 가진 결과값들을 모두 더해서 다시 똑같이 나눠 갖는 All-Reduce를 수행합니다.이 과정에서 모든 GPU가 전체 결과(Full Sequence)를 똑같이 복사해서 들고 있게 되어 메모리 낭비가 발생합니다.
* TP + SP 조합 (Reduce-Scatter & All-Gather 사용):Reduce-Scatter: 연산 결과를 합치되, 각 GPU가 자기 담당 구역(시퀀스 조각)만 챙겨간다. 덕분에 다른 GPU의 데이터는 버릴 수 있어 메모리가 절약된다.
* All-Gather: 다음 층의 연산을 위해 전체 문장 데이터가 필요할 때만 잠시 흩어져 있는 조각들을 모아 온다.

### 2. "공짜"나 다름없는 효율성 가장 큰 장점은 통신 비용(데이터 전송량)이 동일하다는 것입니다. ###
분산 컴퓨팅 이론상 All-Reduce = Reduce-Scatter + All-Gather와 같기 때문입니다. 
* 추가 비용 없음: TP에서 어차피 해야 할 통신을 두 단계로 쪼개서 수행하는 것뿐이라 전체 데이터 전송량은 늘어나지 않습니다.
* 성능 이득: 통신량은 같은데 활성화 메모리(Activation Memory)는 GPU 개수(\(P\))만큼 나눈 \(1/P\) 수준으로 줄어듭니다.따라서 더 큰 모델이나 긴 문장을 처리할 수 있게 됩니다.

### 3. 통신 최적화 기술 최신 프레임워크(예: NVIDIA Megatron-LM, NeMo)는 이 통신마저도 숨기기 위해 노력합니다. 
* Communication Overlap: All-Gather로 데이터를 모으는 동안 놀지 않고 다른 연산을 미리 수행하는 방식으로 통신 지연 시간을 가립니다.
* 고속 링크 필수: TP와 SP는 레이어마다 빈번한 통신이 필요하므로, NVLink 같은 초고속 대역폭을 갖춘 노드 내부(Intra-node)에서 주로 사용됩니다.
결론적으로, SP는 통신 오버헤드를 늘리지 않으면서 메모리 병목을 해결하는 매우 영리한 전략입니다. 


## 실제 학습 속도(Throughput)에 얼마나 영향 ##

시퀀스 병렬화(SP)와 통신 최적화가 실제 학습 속도(Throughput)에 미치는 영향은 단순한 수치 이상의 전략적 이득을 제공합니다. 

### 1. 활성화 메모리 절감과 처리량 향상 ###
시퀀스 병렬화의 가장 큰 목적은 활성화 재계산(Activation Recomputation) 횟수를 줄이는 것입니다. 메모리가 부족하면 어쩔 수 없이 중간값을 버리고 나중에 다시 계산해야 하는데, SP는 이 낭비를 막아줍니다. 
* 메모리 효율: SP를 사용하면 텐서 병렬화(TP)에서 중복 저장되던 활성화 메모리를 최대 병렬화 개수(TP degree)만큼 반감시킬 수 있습니다.
* 재계산 오버헤드 제거: 활성화 값을 모두 다시 계산(Full Recompute)할 경우 발생하는 30~40%의 실행 시간 손해(Execution Time Overhead)를 SP를 통해 메모리를 확보함으로써 방지할 수 있습니다.
* 배치 사이즈 증대: 동일 메모리 환경에서 SP 적용 시 적용 전보다 최대 13.7배 더 큰 배치 사이즈 혹은 3배 더 긴 문장(Sequence Length)을 처리할 수 있어, 전체적인 시간당 토큰 처리량(Throughput)이 비약적으로 상승합니다.
  
### 2. 통신 비용의 효율성 (0%의 추가 부담) ###
SP는 통신 방식만 바꿀 뿐 데이터 전송량 자체를 늘리지 않기 때문에 속도 저하가 거의 없습니다.
* 통신량 보존: All-Reduce 연산을 Reduce-Scatter와 All-Gather로 쪼개어 수행하는 방식은 이론적·실무적으로 통신량이 동일합니다. 따라서 통신 속도 때문에 학습이 느려지는 일은 발생하지 않습니다.
* 컴퓨팅 밀도: 연산량이 적은 레이어(LayerNorm, Dropout 등)를 병렬화하기 때문에, CPU 병목이나 커널 실행 오버헤드가 줄어들어 하드웨어 활용률(MFU, Model FLOPs Utilization)을 50% 이상 유지하는 데 도움을 줍니다.
 
### 3. 하드웨어 성능 체감 (예시 수치) ###
최신 NVIDIA NeMo Framework를 활용한 거대 모델 학습 시: 
* 최대 성능: GPU당 190~280 TFLOPs/sec의 연산 속도를 기록하며, 초당 최대 13,000개 이상의 토큰을 처리할 수 있는 최적화된 처리량을 보여줍니다.
* 실제 사례: 1조 개 파라미터(1T) 모델 학습 시, 이러한 병렬화 최적화 없이는 수천 년이 걸릴 작업을 약 3개월 수준으로 단축하는 핵심 기술로 작동합니다. 

결론적으로, SP는 통신 지연 시간을 늘리지 않으면서도 메모리 한계로 인한 재계산 비용(30%+)을 아껴주므로, 대규모 학습에서 실질적으로 1.3~1.5배 이상의 Throughput 향상 효과를 가져온다고 볼 수 있습니다.


## 밴치마크 ##

### 1. GPU 모델별 성능 체감 (H100 vs A100) ###
H100은 Transformer Engine과 더 넓은 대역폭을 가져 SP 효율이 극대화됩니다.
* A100 (80GB): 메모리 대역폭 한계로 인해 모델이 커질수록 SP 없이 배치 사이즈를 키우기가 매우 어렵습니다. SP 적용 시 재계산(Recomputation)을 줄여 약 20~30%의 전체 Throughput 향상을 보입니다.
* H100 (80GB): FP8 연산과 결합된 SP는 압도적인 속도를 냅니다. NVIDIA의 H100 벤치마크에 따르면, 최적화된 병렬화 적용 시 GPU당 최대 700~900 TFLOPS 수준의 성능을 뽑아내며, 이는 A100 대비 3배 이상 빠른 수치입니다.

### 2. 모델 크기별 구체적 수치 (Llama 2 기준) ###
70B 이상의 대형 모델에서는 SP 유무가 '학습 가능 여부'를 결정짓기도 합니다

|모델 크기|	주요 병목 지점|	SP 적용 시 효과 (Throughput)|	비고|
|7B ~ 13B|	연산 위주 (Compute-bound)|	5~10% 향상|	모델이 작아 메모리 여유가 있어 효과가 낮음|
|70B (Llama 2)|	메모리 위주 (Memory-bound)|	25~40% 향상|	활성화 재계산을 안 해도 되어 속도가 급증함|
|175B (GPT-3급)|	통신 및 메모리 병목| 1.5배 이상 향상|	긴 시퀀스(8K 이상) 학습 시 필수적|
