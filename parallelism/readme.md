## TP vs TP+SP ##

모델이 커지면 학습 과정에서 데이터를 저장하는 활성화 메모리(Activation Memory)가 그래픽 카드(GPU) 용량을 초과하는 병목 현상이 발생한다. 이를 해결하기 위해 텐서 병렬화(Tensor Parallel, TP)를 사용하지만, TP만으로는 부족한 부분을 시퀀스 병렬화(Sequence Parallel, SP)가 채워주게 된다. 

### 1. 왜 활성화 메모리가 병목인가요? ###
학습할 때 역전파(Backpropagation)를 위해 forward 단계의 중간값(활성화 값)을 메모리에 계속 들고 있어야 한다. 모델이 커지고 문장(Sequence)이 길어질수록 이 데이터 양이 기하급수적으로 늘어나 GPU 메모리를 다 잡아먹게 된다. 

### 2. 텐서 병렬화(TP)의 한계 ###
TP는 연산량이 많은 Attention이나 MLP 층의 행렬을 쪼개서 여러 GPU가 나눠 갖게 한다. 하지만 LayerNorm이나 RMSNorm 같은 층은 연산량은 적으면서도 전체 시퀀스 데이터를 그대로 복사해서 들고 있어야 하므로, 여기서 메모리 낭비가 발생한다. 

### 3. 시퀀스 병렬화(SP)의 역할 ###
SP는 바로 이 LayerNorm/RMSNorm 층에서 데이터를 시퀀스(문장 길이) 방향으로 쪼개서 각 GPU에 나눠 준다. 
* 기존 TP: 모든 GPU가 똑같은 전체 문장 데이터를 복사해서 들고 있음.
* SP 적용 시: 1번 GPU는 문장의 앞부분, 2번 GPU는 뒷부분만 들고 연산함.
* 결과: 각 GPU가 저장해야 할 활성화 메모리 양이 병렬화 개수만큼 줄어들어, 더 긴 문장이나 더 큰 모델을 학습할 수 있게 된다. 
요약하자면, "연산이 무거운 곳은 TP로, 연산은 가볍지만 메모리를 많이 먹는 Norm 층은 SP로 쪼개서" 전체적인 메모리 효율을 극대화하는 전략이다. 

## SP 의 장점 ##
시퀀스 병렬화(SP)를 도입하면 통신 방식이 All-Reduce 방식에서 Reduce-Scatter와 All-Gather의 조합으로 바뀐다. 핵심은 "통신량은 그대로인데, 메모리 효율은 극대화된다"는 점입이다. 

### 1. 통신 방식의 변화 (TP vs TP+SP) ###
기존의 텐서 병렬화(TP)만 사용할 때와 SP를 추가했을 때의 통신 과정을 비교하면 이해가 쉽다. 
* 기존 TP (All-Reduce 사용):연산이 끝나면 각 GPU가 가진 결과값들을 모두 더해서 다시 똑같이 나눠 갖는 All-Reduce를 수행합니다.이 과정에서 모든 GPU가 전체 결과(Full Sequence)를 똑같이 복사해서 들고 있게 되어 메모리 낭비가 발생합니다.
* TP + SP 조합 (Reduce-Scatter & All-Gather 사용):Reduce-Scatter: 연산 결과를 합치되, 각 GPU가 자기 담당 구역(시퀀스 조각)만 챙겨간다. 덕분에 다른 GPU의 데이터는 버릴 수 있어 메모리가 절약된다.
* All-Gather: 다음 층의 연산을 위해 전체 문장 데이터가 필요할 때만 잠시 흩어져 있는 조각들을 모아 온다.

### 2. "공짜"나 다름없는 효율성 가장 큰 장점은 통신 비용(데이터 전송량)이 동일하다는 것입니다. ###
분산 컴퓨팅 이론상 All-Reduce = Reduce-Scatter + All-Gather와 같기 때문입니다. 
* 추가 비용 없음: TP에서 어차피 해야 할 통신을 두 단계로 쪼개서 수행하는 것뿐이라 전체 데이터 전송량은 늘어나지 않습니다.
* 성능 이득: 통신량은 같은데 활성화 메모리(Activation Memory)는 GPU 개수(\(P\))만큼 나눈 \(1/P\) 수준으로 줄어듭니다.따라서 더 큰 모델이나 긴 문장을 처리할 수 있게 됩니다.

### 3. 통신 최적화 기술 최신 프레임워크(예: NVIDIA Megatron-LM, NeMo)는 이 통신마저도 숨기기 위해 노력합니다. 
* Communication Overlap: All-Gather로 데이터를 모으는 동안 놀지 않고 다른 연산을 미리 수행하는 방식으로 통신 지연 시간을 가립니다.
* 고속 링크 필수: TP와 SP는 레이어마다 빈번한 통신이 필요하므로, NVLink 같은 초고속 대역폭을 갖춘 노드 내부(Intra-node)에서 주로 사용됩니다.
결론적으로, SP는 통신 오버헤드를 늘리지 않으면서 메모리 병목을 해결하는 매우 영리한 전략입니다. 


## 실제 학습 속도(Throughput)에 얼마나 영향 ##

시퀀스 병렬화(SP)와 통신 최적화가 실제 학습 속도(Throughput)에 미치는 영향은 단순한 수치 이상의 전략적 이득을 제공합니다. 

### 1. 활성화 메모리 절감과 처리량 향상 ###
시퀀스 병렬화의 가장 큰 목적은 활성화 재계산(Activation Recomputation) 횟수를 줄이는 것입니다. 메모리가 부족하면 어쩔 수 없이 중간값을 버리고 나중에 다시 계산해야 하는데, SP는 이 낭비를 막아줍니다. 
* 메모리 효율: SP를 사용하면 텐서 병렬화(TP)에서 중복 저장되던 활성화 메모리를 최대 병렬화 개수(TP degree)만큼 반감시킬 수 있습니다.
* 재계산 오버헤드 제거: 활성화 값을 모두 다시 계산(Full Recompute)할 경우 발생하는 30~40%의 실행 시간 손해(Execution Time Overhead)를 SP를 통해 메모리를 확보함으로써 방지할 수 있습니다.
* 배치 사이즈 증대: 동일 메모리 환경에서 SP 적용 시 적용 전보다 최대 13.7배 더 큰 배치 사이즈 혹은 3배 더 긴 문장(Sequence Length)을 처리할 수 있어, 전체적인 시간당 토큰 처리량(Throughput)이 비약적으로 상승합니다.
  
### 2. 통신 비용의 효율성 (0%의 추가 부담) ###
SP는 통신 방식만 바꿀 뿐 데이터 전송량 자체를 늘리지 않기 때문에 속도 저하가 거의 없습니다.
* 통신량 보존: All-Reduce 연산을 Reduce-Scatter와 All-Gather로 쪼개어 수행하는 방식은 이론적·실무적으로 통신량이 동일합니다. 따라서 통신 속도 때문에 학습이 느려지는 일은 발생하지 않습니다.
* 컴퓨팅 밀도: 연산량이 적은 레이어(LayerNorm, Dropout 등)를 병렬화하기 때문에, CPU 병목이나 커널 실행 오버헤드가 줄어들어 하드웨어 활용률(MFU, Model FLOPs Utilization)을 50% 이상 유지하는 데 도움을 줍니다.
 
### 3. 하드웨어 성능 체감 (예시 수치) ###
최신 NVIDIA NeMo Framework를 활용한 거대 모델 학습 시: 
* 최대 성능: GPU당 190~280 TFLOPs/sec의 연산 속도를 기록하며, 초당 최대 13,000개 이상의 토큰을 처리할 수 있는 최적화된 처리량을 보여줍니다.
* 실제 사례: 1조 개 파라미터(1T) 모델 학습 시, 이러한 병렬화 최적화 없이는 수천 년이 걸릴 작업을 약 3개월 수준으로 단축하는 핵심 기술로 작동합니다. 

결론적으로, SP는 통신 지연 시간을 늘리지 않으면서도 메모리 한계로 인한 재계산 비용(30%+)을 아껴주므로, 대규모 학습에서 실질적으로 1.3~1.5배 이상의 Throughput 향상 효과를 가져온다고 볼 수 있습니다.


## 밴치마크 ##

### 1. GPU 모델별 성능 체감 (H100 vs A100) ###
H100은 Transformer Engine과 더 넓은 대역폭을 가져 SP 효율이 극대화됩니다.
* A100 (80GB): 메모리 대역폭 한계로 인해 모델이 커질수록 SP 없이 배치 사이즈를 키우기가 매우 어렵습니다. SP 적용 시 재계산(Recomputation)을 줄여 약 20~30%의 전체 Throughput 향상을 보입니다.
* H100 (80GB): FP8 연산과 결합된 SP는 압도적인 속도를 냅니다. NVIDIA의 H100 벤치마크에 따르면, 최적화된 병렬화 적용 시 GPU당 최대 700~900 TFLOPS 수준의 성능을 뽑아내며, 이는 A100 대비 3배 이상 빠른 수치입니다.

### 2. 모델 크기별 구체적 수치 (Llama 2 기준) ###
70B 이상의 대형 모델에서는 SP 유무가 '학습 가능 여부'를 결정짓기도 합니다

|모델 크기|	주요 병목 지점|	SP 적용 시 효과 (Throughput)|	비고|
|------|---|---|---|
|7B ~ 13B|	연산 위주 (Compute-bound)|	5~10% 향상|	모델이 작아 메모리 여유가 있어 효과가 낮음|
|70B (Llama 2)|	메모리 위주 (Memory-bound)|	25~40% 향상|	활성화 재계산을 안 해도 되어 속도가 급증함|
|175B (GPT-3급)|	통신 및 메모리 병목| 1.5배 이상 향상|	긴 시퀀스(8K 이상) 학습 시 필수적|

### 3. 실제 TFLOPS 및 효율성(MFU) 데이터 ###
NVIDIA Megatron-LM 논문과 기술 블로그에 따르면, 5,120개의 GPU를 사용한 대규모 클러스터에서 다음과 같은 수치를 기록했습니다.
* MFU (Model FLOPs Utilization): SP와 TP 최적화가 잘 된 경우 약 46% ~ 52%의 효율을 달성합니다. (최적화가 안 되면 30% 이하로 추락)
* Inter-node 통신: SP는 주로 노드 내부(Intra-node)의 NVLink를 활용하여 900GB/s 이상의 대역폭을 사용하므로, 통신으로 인한 속도 저하를 1% 미만으로 억제합니다.

### 4. 시퀀스 길이에 따른 성능 차이 ###
최근 32K, 128K 같은 Long Context 학습이 중요해지면서 SP의 수치는 더 극적으로 변합니다.

* 2K Context: SP 효과 보통.
* 32K Context 이상: SP 없이는 GPU 하나에 문장 한 개도 못 올리는 현상 발생. SP 적용 시에만 정상적인 Throughput(초당 수천 토큰)이 산출됨.
결론적으로, H100 환경에서 70B 이상의 모델을 학습할 때 SP와 통신 최적화를 적용하면, 적용 전보다 최소 30%에서 최대 수 배까지의 실제 학습 속도(Tokens/sec) 이득을 얻을 수 있습니다.

## 예상 ##

총 640개의 H100 GPU를 사용하는 대규모 클러스터(80노드) 규모에서는 시퀀스 병렬화(SP)와 통신 최적화가 단순한 옵션이 아닌, 학습 성패를 가르는 핵심 변수가 됩니다. 

### 1. 예상 처리량(Throughput) 및 연산 효율 ###
640대의 H100 시스템에서 최적의 병렬화(TP8 + SP + PP8 + DP10 등)를 구성했을 때의 예상 수치입니다.
* GPU당 성능: FP8 연산 기준, 노드 당 3.2Tbps의 InfiniBand 대역폭이 뒷받침될 경우 GPU당 약 600~750 TFLOPS를 기대할 수 있습니다.
* MFU (Model FLOPs Utilization): 80노드 규모에서는 통신 오버헤드가 증가하지만, NVIDIA NeMo Framework 기준 약 45%~50% 수준의 MFU를 유지하는 것이 목표치입니다.
* 학습 속도: Llama 3 70B 모델 기준, 초당 약 150,000 ~ 200,000개 이상의 토큰을 처리할 수 있는 규모입니다.

### 2. 통신 최적화의 핵심: 계층적 구조 ###
80노드 클러스터에서는 노드 내부(Intra-node)와 노드 간(Inter-node) 통신 속도 차이를 관리하는 것이 핵심입니다.
* 노드 내부 (NVLink): 8개의 GPU가 NVLink Switch System으로 연결되어 900GB/s의 압도적인 속도로 SP/TP 통신을 처리합니다. 여기서 발생하는 지연 시간은 거의 0에 가깝습니다.
* 노드 간 (InfiniBand/RoCE): 데이터 병렬화(DP)나 파이프라인 병렬화(PP) 통신이 일어납니다. H100 노드는 보통 400Gbps NDR 인피니밴드 8개를 탑재하므로, 노드 간 병목을 최소화합니다.
* SP의 기여: 80노드 규모에서 SP를 쓰지 않으면 메모리 부족으로 인해 Activation Checkpointing을 강하게 걸어야 합니다. SP를 적용하면 이 체크포인팅을 줄여 전체 학습 속도를 20~30% 즉각적으로 향상시킵니다.

### 3. 클러스터 규모에서의 병목 현상과 해결책 ###
80노드(640 GPU) 환경에서 흔히 발생하는 수치적 이슈는 다음과 같습니다.
* 통신 오버헤드: GPU 개수가 늘어날수록 All-Reduce 시간이 길어지지만, SP는 이를 Reduce-Scatter/All-Gather로 쪼개고 연산과 Overlap(중첩)시켜 통신 시간을 계산 시간 뒤로 숨깁니다.
* 성능 저하 방지: 통신 최적화가 안 된 80노드 클러스터는 개별 GPU 성능의 30%도 못 쓰는 경우가 많으나, 최적화 시 이를 1.5배 이상(45%+)으로 끌어올릴 수 있습니다.

### 4. 권장 병렬화 설정 (H100 640개 기준) ###
* TP (Tensor Parallel): 8 (한 노드의 모든 GPU 사용, NVLink 활용 극대화)
* SP (Sequence Parallel): ON (LayerNorm/Dropout 메모리 절감)
* PP (Pipeline Parallel): 4 ~ 8 (노드 간 통신 최적화)
* DP (Data Parallel): 나머지 (80 ~ 160)

모델 크기에 따라 PP(파이프라인 병렬화)와 DP(데이터 병렬화)의 최적 비율이 달라지는데, 이에 대해 더 상세히 계산해 드릴 수 있습니다.

## ##
640개의 H100 GPU(80노드) 클러스터에서 Llama 3 70B 모델을 학습한다고 가정하고, 최적의 병렬화 조합과 그에 따른 성능 수치를 계산해 드립니다. 

### 1. 병렬화 설정 (Parallelism Strategy) ###
H100의 성능을 극대화하기 위해 노드 내부는 NVLink, 노드 간은 InfiniBand 대역폭을 고려하여 다음과 같이 분배하는 것이 정석입니다. 
* TP (Tensor Parallel): 8
  * 이유: 한 노드(8 GPU) 내부의 NVLink 대역폭(900GB/s)을 100% 활용합니다.
* SP (Sequence Parallel): ON
  * 이유: TP8 사용 시 발생하는 LayerNorm 등의 중복 메모리를 제거하여 배치 사이즈를 확보합니다.
* PP (Pipeline Parallel): 4
  * 이유: 80개 노드를 20개 그룹으로 나눕니다. PP가 너무 크면 Bubble(대기 시간)이 발생하므로 4~8 사이가 적당합니다.
* DP (Data Parallel): 20
  * 이유: \(640/(8\times 4)=20\). 실제로는 성능 향상을 위해 ZeRO-1/2 (Distributed Optimizer)를 결합합니다.

### 2. 메모리 및 속도 계산 (수치 중심) ###
#### ① 활성화 메모리 (Activation Memory) #### 
* SP 적용 전: 시퀀스 길이 4k 기준, 약 20GB 이상의 활성화 메모리 필요.
* SP 적용 후: 약 2.5GB~3GB로 감소 (TP8로 쪼개짐).
* 이득: 남는 메모리에 배치 사이즈(Micro-batch size)를 4~8배 키울 수 있어 연산 효율(Throughput)이 약 30% 상승합니다.

#### ② 예상 연산 속도 (TFLOPS) #### 
* H100 FP8 Peak: 1,979 TFLOPS (Sparse 기준이나 실제 학습은 Dense 기준 약 900~1000 TFLOPS)
* 실제 달성 목표 (MFU 45% 가정): GPU당 약 450 TFLOPS
* 클러스터 전체 성능: \(640\times 450\text{\ TFLOPS}\approx \mathbf{288}\text{\ PetaFLOPS}\)

#### ③ 토큰 처리량 (Tokens/sec) #### 
70B 모델의 1회 Forward/Backward 연산량은 약 \(6\times 70\times 10^{9}=420\text{\ GFLOPS/token}\)입니다. 
* 초당 토큰 처리량: \(288\text{\ PetaFLOPS}/420\text{\ GFLOPS}\approx \mathbf{685,000}\text{\ tokens/sec}\)
* 하루 학습량: 약 590억 개(59B) 토큰 학습 가능.

### 3. 통신 오버헤드 체크 ###
* Intra-node (SP/TP): 900GB/s NVLink 덕분에 통신 시간이 전체 연산 시간의 3% 미만으로 억제됩니다.
* Inter-node (DP): NVIDIA Quantum-2 InfiniBand를 통해 노드당 400Gbps \(\times \) 8개를 사용하면, Gradient 변수 공유 시 발생하는 병목을 거의 완벽하게 가릴 수(Overlap) 있습니다.

### 4. 최종 요약 ##
* 항목 예상 수치
  * GPU당 실질 연산력~450 TFLOPS (H100 최적화 기준)
  * 일일 토큰 학습량약 59B Tokens (Llama 3 70B 기준)
  * SP 적용 이득메모리 8배 절감 → 배치 사이즈 증대로 전체 속도 ~30% 향상권장
  * 프레임워크: Megatron-Core 또는 NVIDIA NeMo이 계산은 시퀀스 길이 4k를 기준으로 한 것입니다.
 
