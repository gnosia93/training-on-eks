## TP vs TP+SP ##

모델이 커지면 학습 과정에서 데이터를 저장하는 활성화 메모리(Activation Memory)가 그래픽 카드(GPU) 용량을 초과하는 병목 현상이 발생한다. 이를 해결하기 위해 텐서 병렬화(Tensor Parallel, TP)를 사용하지만, TP만으로는 부족한 부분을 시퀀스 병렬화(Sequence Parallel, SP)가 채워주게 된다. 

### 1. 왜 활성화 메모리가 병목인가요? ###
학습할 때 역전파(Backpropagation)를 위해 forward 단계의 중간값(활성화 값)을 메모리에 계속 들고 있어야 한다. 모델이 커지고 문장(Sequence)이 길어질수록 이 데이터 양이 기하급수적으로 늘어나 GPU 메모리를 다 잡아먹게 된다. 

### 2. 텐서 병렬화(TP)의 한계 ###
TP는 연산량이 많은 Attention이나 MLP 층의 행렬을 쪼개서 여러 GPU가 나눠 갖게 한다. 하지만 LayerNorm이나 RMSNorm 같은 층은 연산량은 적으면서도 전체 시퀀스 데이터를 그대로 복사해서 들고 있어야 하므로, 여기서 메모리 낭비가 발생한다. 

### 3. 시퀀스 병렬화(SP)의 역할 ###
SP는 바로 이 LayerNorm/RMSNorm 층에서 데이터를 시퀀스(문장 길이) 방향으로 쪼개서 각 GPU에 나눠 준다. 
* 기존 TP: 모든 GPU가 똑같은 전체 문장 데이터를 복사해서 들고 있음.
* SP 적용 시: 1번 GPU는 문장의 앞부분, 2번 GPU는 뒷부분만 들고 연산함.
* 결과: 각 GPU가 저장해야 할 활성화 메모리 양이 병렬화 개수만큼 줄어들어, 더 긴 문장이나 더 큰 모델을 학습할 수 있게 된다. 
요약하자면, "연산이 무거운 곳은 TP로, 연산은 가볍지만 메모리를 많이 먹는 Norm 층은 SP로 쪼개서" 전체적인 메모리 효율을 극대화하는 전략이다. 

## SP 의 장점 ##
시퀀스 병렬화(SP)를 도입하면 통신 방식이 All-Reduce 방식에서 Reduce-Scatter와 All-Gather의 조합으로 바뀐다. 핵심은 "통신량은 그대로인데, 메모리 효율은 극대화된다"는 점입이다. 

### 1. 통신 방식의 변화 (TP vs TP+SP) ###
기존의 텐서 병렬화(TP)만 사용할 때와 SP를 추가했을 때의 통신 과정을 비교하면 이해가 쉽다. 
* 기존 TP (All-Reduce 사용):연산이 끝나면 각 GPU가 가진 결과값들을 모두 더해서 다시 똑같이 나눠 갖는 All-Reduce를 수행합니다.이 과정에서 모든 GPU가 전체 결과(Full Sequence)를 똑같이 복사해서 들고 있게 되어 메모리 낭비가 발생합니다.
* TP + SP 조합 (Reduce-Scatter & All-Gather 사용):Reduce-Scatter: 연산 결과를 합치되, 각 GPU가 자기 담당 구역(시퀀스 조각)만 챙겨간다. 덕분에 다른 GPU의 데이터는 버릴 수 있어 메모리가 절약된다.
* All-Gather: 다음 층의 연산을 위해 전체 문장 데이터가 필요할 때만 잠시 흩어져 있는 조각들을 모아 온다.

### 2. "공짜"나 다름없는 효율성 가장 큰 장점은 통신 비용(데이터 전송량)이 동일하다는 것입니다. ###
분산 컴퓨팅 이론상 All-Reduce = Reduce-Scatter + All-Gather와 같기 때문입니다. 
* 추가 비용 없음: TP에서 어차피 해야 할 통신을 두 단계로 쪼개서 수행하는 것뿐이라 전체 데이터 전송량은 늘어나지 않습니다.
* 성능 이득: 통신량은 같은데 활성화 메모리(Activation Memory)는 GPU 개수(\(P\))만큼 나눈 \(1/P\) 수준으로 줄어듭니다.따라서 더 큰 모델이나 긴 문장을 처리할 수 있게 됩니다.

### 3. 통신 최적화 기술 최신 프레임워크(예: NVIDIA Megatron-LM, NeMo)는 이 통신마저도 숨기기 위해 노력합니다. 
* Communication Overlap: All-Gather로 데이터를 모으는 동안 놀지 않고 다른 연산을 미리 수행하는 방식으로 통신 지연 시간을 가립니다.
* 고속 링크 필수: TP와 SP는 레이어마다 빈번한 통신이 필요하므로, NVLink 같은 초고속 대역폭을 갖춘 노드 내부(Intra-node)에서 주로 사용됩니다.
결론적으로, SP는 통신 오버헤드를 늘리지 않으면서 메모리 병목을 해결하는 매우 영리한 전략입니다. 
