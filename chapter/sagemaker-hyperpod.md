### 1. 상시 상태 모니터링 (Health Monitoring Agent) ### 
HyperPod는 모든 GPU 및 Trainium 노드에서 백그라운드로 실행되는 상태 모니터링 에이전트를 사용합니다. 
* 패시브 체크: GPU 응답성, NVLink 오류 카운터, 메모리 고갈(OOM), 커널 데드락 등 하드웨어 및 시스템 수준의 결함을 실시간으로 감시합니다.
* 딥 헬스 체크(Deep Health Checks): 새로운 인스턴스가 클러스터에 추가될 때 EFA(Elastic Fabric Adapter) 네트워크와 GPU의 부하 테스트를 수행하여 불량 노드가 사전에 투입되는 것을 방지합니다. 

### 2. 자동 노드 복구 및 교체 (Self-Healing) ###
장애가 감지되면 시스템이 즉시 개입하여 클러스터의 복원력을 유지합니다.
* 지능적 판단: 문제의 경중에 따라 노드를 단순히 재부팅(Reboot)하거나, 하드웨어 결함인 경우 정상적인 새 인스턴스로 교체(Replace)합니다.
* 자동화: 2025년에 도입된 최신 기능을 통해 사용자는 별도의 수동 구성 없이도 에이전트가 노드를 'Unhealthy'로 표시하고 자동으로 복구 작업을 시작하도록 설정할 수 있습니다. 

### 3. 체크포인트 기반 자동 재개 (Auto-Resume) ###
노드 교체 후 중단된 지점부터 다시 학습을 시작합니다.
* Job Auto-Resume: Slurm 또는 Kubernetes(EKS) 오케스트레이터와 통합되어, 새 노드가 준비되면 마지막으로 저장된 체크포인트(Checkpoint)를 자동으로 로드하여 훈련을 재개합니다.
* 중단 최소화: 수동으로 작업을 다시 제출할 필요가 없으므로 관리자의 운영 부담이 0에 가깝습니다. 

### 4. 2025년 신기술: 체크포인트리스 훈련 (Checkpointless Training) ###
최근에는 저장 장치에 체크포인트를 쓰는 시간을 줄이기 위해 더 진보된 방식이 도입되었습니다.
* P2P 상태 복구: 장애 발생 시 전체 작업을 멈추고 체크포인트를 읽어오는 대신, 정상적인 인접 노드(Peer)로부터 모델 및 옵티마이저 상태를 직접 전송받아 복구합니다.
* 효율성: 이 방식을 통해 복구 시간을 기존 수십 분에서 2분 미만으로 단축할 수 있으며, 수천 개의 GPU 클러스터에서도 95% 이상의 가동률(Goodput)을 유지할 수 있습니다. 
이 시스템 덕분에 기업은 수개월이 걸리는 LLM 훈련 과정에서 발생할 수 있는 하드웨어 장애 리스크를 최소화하고, 유휴 자원 낭비 없이 안정적으로 모델을 개발할 수 있습니다. 
