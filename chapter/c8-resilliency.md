2025년 기준, Torch Elastic(torchrun)과 쿠버네티스의 조합은 분산 학습의 가용성을 높이는 매우 강력한 도구입니다. 
"포드 하나만 다시 띄워 그룹을 재형성하는 과정"이 구체적으로 어떻게 구현되는지 정리해 드립니다.

#### 1. 랑데부(Rendezvous) 시스템의 역할 ####
torchrun의 핵심은 랑데부라는 중앙 체크인 시스템입니다. (주로 ETCD나 Kubernetes API 서버를 백엔드로 사용합니다.)
* 멤버십 관리: 모든 노드(Pod)는 시작 시 랑데부 서버에 자신을 등록합니다.
* 동적 그룹 형성: 설정된 최소(min) 및 최대(max) 노드 수만 만족되면, 일부 노드가 늦게 뜨거나 일찍 떠도 전체 그룹(World Size)을 유동적으로 구성합니다.

#### 2. 장애 발생 시 복구 프로세스 (Step-by-Step) ####
노드 1개가 죽었을 때, 일반적인 NCCL 훈련과 달리 torchrun은 다음과 같이 행동합니다.
* 장애 감지: 특정 Pod가 죽으면 NCCL 통신이 깨집니다. 이때 살아있는 나머지 Pod의 torchrun 프로세스가 이를 감지하고 자신의 로컬 프로세스들을 모두 종료(Terminate)시킵니다. (전체 작업은 잠시 멈춥니다.)
* 쿠버네티스 재스케줄링: 쿠버네티스의 Job 컨트롤러나 ReplicaSet이 죽은 Pod를 감지하고, 새로운 Pod를 자동으로 다시 생성합니다.
* 새로운 랑데부: 새로 뜬 Pod와 기존에 살아있던 Pod들이 다시 랑데부 서버에 모입니다.
* World 재구성: 랑데부 서버는 "자, 다시 8명이 모였으니 새로 시작하자"라고 신호를 보냅니다. 이때 바뀐 IP 정보 등을 NCCL에 다시 전파하여 통신 그룹을 재형성(Re-init)합니다.
* 학습 재개: 개발자가 짠 코드 내의 load_checkpoint 로직에 의해 공유 스토리지에서 마지막 상태를 불러와 학습을 이어갑니다.

#### 3. HyperPod + EKS 환경에서의 시너지 ####
HyperPod 위에서 torchrun을 쓰면 일반 EKS보다 더 강력해집니다.
* 인프라 수준의 수리: 일반 EKS는 하드웨어가 고장 나면 Pod가 계속 Pending 상태에 머물 수 있지만, HyperPod는 즉시 새 EC2 노드를 공급하여 torchrun이 다시 모일 자리를 만들어줍니다.
* 정교한 종료 처리: HyperPod는 노드 장애가 발생하기 전 징후를 미리 포착하고, torchrun에게 미리 신호를 보내 체크포인트를 안전하게 저장한 뒤 재시작하게 유도할 수 있습니다.

#### 4. 개발자가 신경 써야 할 설정 ####
이 기능을 제대로 쓰려면 torchrun 실행 시 다음과 같은 인자값을 설정해야 합니다.
* --nnodes=1:8: 최소 1대에서 최대 8대까지 가변적으로 운영하겠다는 설정 (노드 1개가 죽어도 나머지로 계속할지, 아니면 다시 채울 때까지 기다릴지 결정).
* --rdzv_backend=etcd (또는 c10d): 랑데부 정보를 어디에 저장할지 지정.
* --max_restarts=3: 무한 루프 방지를 위해 최대 몇 번까지 자동 복구를 시도할지 설정.

#### 요약 ####
torchrun은 "통신 그룹을 다시 묶어주는 소프트웨어적 접착제"이고, EKS(HyperPod)는 "죽은 포드를 다시 살려내고 하드웨어를 제공하는 인프라 엔진"입니다. 이 두 개가 결합되어야만 진정한 의미의 Fault-tolerant 분산 학습이 완성됩니다.
관련하여 더 자세한 구현 예시는 PyTorch Elastic 공식 문서에서 확인하실 수 있습니다.


## 레퍼런스 ##

* [Building Resilience for Large-Scale AI Training: GPU Management](https://www.youtube.com/watch?v=iam7A5peA5U)
* 
