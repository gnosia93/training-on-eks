
Magnum IO는 NVIDIA가 만든 "데이터 이동의 최적화 도구 모음(Software Stack)" 이다.
GPU 연산이 아무리 빨라도 데이터를 가져오는 속도가 느리면 전체 연산 효율이 떨어지게 된다. 그래서 NVIDIA는 데이터가 저장소나 네트워크에서 GPU로 들어오는 모든 경로를 광속으로 만들기 위해 이 기술 들을 개발하였다.

#### 1. GPUDirect Storage (GDS) ####
* 역할: 데이터가 SSD → CPU 메모리 → GPU를 거치지 않고, SSD → GPU로 직접 쏴버리는 기술이다.
* 효과: CPU 부하를 줄이고 데이터 로딩 속도를 최대 2~3배 높인다.

#### 2. GPUDirect RDMA & P2P #### 
* 역할: 서버와 서버 사이(RDMA), 혹은 한 서버 내 GPU 사이(P2P)에서 데이터를 주고받을 때 CPU를 거치지 않게 한다..
* 연결: 우리가 얘기한 ATS/PASID가 바로 이 RDMA 성능을 극대화하기 위한 하드웨어적 밑바탕이 된다.

#### 3. NCCL (NVIDIA Collective Communications Library) ####
* 역할: 여러 개의 GPU가 동시에 계산할 때(분산 학습), 데이터가 꼬이지 않고 가장 빠른 길로 이동하도록 최적화하는 라이브러리이다.
* 연결: NVLink와 NVSwitch를 가장 잘 활용하도록 설계된 소프트웨어이다

#### 4. NVSHMEM ####
역할: 여러 GPU의 메모리를 마치 하나의 거대한 메모리처럼 보이게 하여, 개발자가 복잡한 복사 명령 없이 데이터를 다룰 수 있게 한다.
