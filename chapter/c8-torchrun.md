torchrun (PyTorch Elastic) 환경에서 하나의 노드에 장애가 발생하면, 나머지 노드들은 무한정 기다리는 것이 아니라 현재 작업을 중단하고 새로운 랑데뷰(Rendezvous)를 통해 재구성을 시도합니다.
구체적인 동작 과정은 다음과 같습니다.

#### 1. 장애 감지 및 전송 (Stop) ####
한 노드가 다운되거나 프로세스가 종료되면, 연결되어 있던 다른 노드들은 통신 타임아웃을 통해 이를 감지합니다. 이 시점에서 모든 생존 노드의 학습 프로세스는 즉시 중단(Panic/Exit)됩니다.

#### 2. 재학습을 위한 재집결 (Rendezvous) ####
torchrun은 설정된 min_nodes와 max_nodes 범위 내에서 다시 랑데뷰를 시도합니다.
* 생존 노드들: 다시 랑데뷰 포인트에 모여 새로운 구성을 기다립니다.
* 장애 노드: 만약 쿠버네티스(Kubernetes) 같은 오케스트레이터가 노드를 복구시킨다면, 해당 노드도 다시 랑데뷰에 참여합니다.
* 대기 시간: --rdzv_timeout 설정값 동안 기다리며, min_nodes 조건이 충족되면 즉시 다음 단계로 넘어갑니다.

#### 3. 재시작 (Restart) ####
새로운 멤버 구성이 완료되면(예: 4개 노드 중 1개가 죽어 3개만 모인 경우), torchrun은 모든 노드의 프로세스를 새로운 RANK와 WORLD_SIZE로 다시 실행합니다.

#### 4. 주의사항: 체크포인트 로드 ####
torchrun은 노드 구성만 자동으로 다시 잡아줄 뿐, 학습 데이터의 상태를 자동으로 복구해주지는 않습니다.
장애 복구 후 이전 단계부터 이어서 학습하려면, 코드 내에 torch.save와 torch.load를 이용한 체크포인트 저장 및 로드 로직이 반드시 구현되어 있어야 합니다.
보통 load_state_dict를 통해 가장 최근에 저장된 모델 파일부터 다시 시작하도록 코드를 짭니다.

#### 요약 ####
노드 장애 시 나머지 노드들은 기다리기만 하는 것이 아니라, 다 같이 멈췄다가 가능한 노드들끼리 모여서 처음부터(또는 마지막 체크포인트부터) 다시 시작합니다.
이것이 python -m torch.distributed.launch와 같은 과거 방식(전체 종료 후 수동 재시작 필요)과 torchrun의 가장 큰 차이점입니다
