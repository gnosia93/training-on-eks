## [íŠ¸ë ˆì´ë‹ ì˜¤í¼ë ˆì´í„°(V2) ì„¤ì¹˜](https://www.kubeflow.org/docs/components/trainer/operator-guides/installation/) ##

V2 ë²„ì „ì˜ íë¸Œ í”Œë¡œìš° íŠ¸ë ˆì´ë‹ ì˜¤í¼ë ˆì´í„°ì™€ ëŸ°í„°ì„ ì„¤ì¹˜í•œë‹¤. 
```
sudo dnf install git -y

export VERSION=v2.1.0
kubectl apply --server-side -k "https://github.com/kubeflow/trainer.git/manifests/overlays/manager?ref=${VERSION}"
kubectl apply --server-side -k "https://github.com/kubeflow/trainer.git/manifests/overlays/runtimes?ref=${VERSION}"

kubectl get pods -n kubeflow-system
kubectl get clustertrainingruntimes

```
[ê²°ê³¼]
```
NAME                                                   READY   STATUS    RESTARTS   AGE
jobset-controller-manager-58555b47c7-ltrck             1/1     Running   0          2m55s
kubeflow-trainer-controller-manager-5b7b978fbf-r24kr   1/1     Running   0          2m55s

NAME                     AGE
deepspeed-distributed    114s
mlx-distributed          114s
torch-distributed        114s
torchtune-llama3.2-1b    114s
torchtune-llama3.2-3b    114s
torchtune-qwen2.5-1.5b   114s
```

## CRD ì¡°íšŒ ##
```
kubectl explain trainjob.spec
kubectl explain trainjob.spec.podTemplateOverrides.spec
```

## runtme ì¡°íšŒ ##
```
kubectl get clustertrainingruntime torch-distributed -o yaml
```
[ê²°ê³¼]
```
apiVersion: trainer.kubeflow.org/v1alpha1
kind: ClusterTrainingRuntime
metadata:
  creationTimestamp: "2025-12-25T17:37:32Z"
  generation: 1
  labels:
    trainer.kubeflow.org/framework: torch
  name: torch-distributed
  resourceVersion: "1310309"
  uid: 2067ff23-511e-4b9c-b37e-b4d873f43c85
spec:
  mlPolicy:
    numNodes: 1
    torch:
      numProcPerNode: auto
  template:
    spec:
      replicatedJobs:
      - groupName: default
        name: node
        replicas: 1
        template:
          metadata:
            labels:
              trainer.kubeflow.org/trainjob-ancestor-step: trainer
          spec:
            template:
              spec:
                containers:
                - image: pytorch/pytorch:2.7.1-cuda12.8-cudnn9-runtime
                  name: node
```
```
kubectl explain ClusterTrainingRuntime.spec.template.spec.failurePolicy.maxRestarts
```
```
GROUP:      trainer.kubeflow.org
KIND:       ClusterTrainingRuntime
VERSION:    v1alpha1

FIELD: maxRestarts <integer>


DESCRIPTION:
    MaxRestarts defines the limit on the number of JobSet restarts.
    A restart is achieved by recreating all active child jobs.
```
### ì¬ì‹œë„ íšŸìˆ˜ ìˆ˜ì • ###
#### 1. ClusterTrainingRuntime ì§ì ‘ ìˆ˜ì • (í•„ìˆ˜) ####
TrainJob íŒŒì¼ì—ì„œ failurePolicyë¥¼ ë¹¼ê³ , ëŒ€ì‹  ëŸ°íƒ€ì„ ìì²´ë¥¼ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
```
kubectl edit clustertrainingruntime torch-distributed
```

ì—ë””í„°ê°€ ì—´ë¦¬ë©´ ì•„ë˜ êµ¬ì¡°ë¥¼ ì°¾ì•„ failurePolicyë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
```
spec:
  template:
    spec:
      # ì—¬ê¸°ì— ì¶”ê°€ (replicatedJobsì™€ ê°™ì€ ë ˆë²¨)
      failurePolicy:
        maxRestarts: 5
      replicatedJobs:
      - name: node
        # ...  
```
* failurePolicy.maxRestartsë¥¼ ì¨ì•¼ í•˜ëŠ” ì´ìœ 
  * ì „ì²´ ì¬ì‹œì‘ (Clean Slate): maxRestartsëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ê´€ë ¨ëœ ëª¨ë“  íŒŒë“œ(ì „ì²´ ì›Œì»¤ë“¤)ë¥¼ í•œêº¼ë²ˆì— ì‚­ì œí•˜ê³  ìƒˆë¡œ ë„ì›ë‹ˆë‹¤.
  * ë‘ë°ë·° ì´ˆê¸°í™”: ëª¨ë“  ë…¸ë“œê°€ ë™ì‹œì— ìƒˆë¡œ ëœ¨ê¸° ë•Œë¬¸ì— ë‘ë°ë·° í¬ì¸íŠ¸ì—ì„œ ë‹¤ì‹œ ê¹”ë”í•˜ê²Œ ëª¨ì—¬ í•™ìŠµì„ ì¬ê°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì´ ë¶„ì‚° í•™ìŠµì—ì„œ í›¨ì”¬ ì•ˆì •ì ì¸ ë³µêµ¬ ë°©ì‹ì…ë‹ˆë‹¤.


## íŠ¸ë ˆì´ë‹ ì‘ì—… ì‹¤í–‰ ##

#### 1. TrainJob ë§Œë“¤ê¸° #### 
```
cat <<EOF > t5-large.yaml
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  name: t5-large
spec:
  podTemplateOverrides:
    - targetJobs:
        - name: node                                                  # ClusterTrainingRuntime ì— ìˆëŠ” runtime job template
      spec:
        nodeSelector:
          node.kubernetes.io/instance-type: g6e.48xlarge              # https://instances.vantage.sh/aws/ec2/g6e.48xlarge?currency=USD
          topology.kubernetes.io/zone: ap-northeast-2a                # AZ ì„¤ì •, ë…¸ë“œ ê°„ í†µì‹  ì§€ì—°ì„ ìµœì†Œí™” 

  runtimeRef:
    name: torch-distributed                   # torch ë¶„ì‚° ë°±ì—”ë“œ ì‚¬ìš© (ê´€ë ¨ íŒŒì´ì¬ íŒ¨í‚¤ì§€ ë¬¶ìŒ)

  trainer:
    numNodes: 2                               # ë…¸ë“œìˆ˜ ì„¤ì •
    numProcPerNode: auto                      # ë…¸ë“œë³„ í”„ë¡œì„¸ìŠ¤ ê°¯ìˆ˜                                                                               
    image: public.ecr.aws/deep-learning-containers/pytorch-training:2.8.0-gpu-py312-cu129-ubuntu22.04-ec2-v1.0

    # ë‘ë°ë·° í¬ì¸íŠ¸ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ê¸°ìˆ í•´ ì¤€ë‹¤(rdzv_id, rdzv_backend, rdzv_endpoint)
    # --rdzv_endpoint=\${MASTER_ADDR}:\${MASTER_PORT} ì—ì„œ \$ í•¨ìœ¼ë¡œì¨ ì‰˜ì´ í•´ë‹¹ ë³€ìˆ˜ë¥¼ í•´ì„í•˜ì§€ ì•Šë„ë¡ í•¨.
    # ${MASTER_ADDR} ì™€ ${MASTER_PORT} í™˜ê²½ë³€ìˆ˜ëŠ” TrainJob ì˜¤í¼ë ˆì´í„°ê°€ ì¡ ì‹¤í–‰ì‹œ ì±„ì›Œì£¼ëŠ” ê°’ì´ë‹¤.  
    command:
      - /bin/bash
      - -c
      - |
        git clone https://github.com/gnosia93/training-on-eks /workspace/code
        cd /workspace/code/samples/fsdp
        pip install -r requirements.txt
        echo "=== Launching Distributed Training ==="
        export MASTER_ADDR=\${PET_MASTER_ADDR}
        export MASTER_PORT=\${PET_MASTER_PORT:-29500}
        echo "Master Address: \${MASTER_ADDR}"
        echo "Master Port: \${MASTER_PORT}"
        echo "=================================="
        torchrun \
          --nproc_per_node=8 \
          --rdzv_id=elastic-job \
          --rdzv_backend=c10d \
          --rdzv_endpoint=\${MASTER_ADDR}:\${MASTER_PORT} \
          t5-fsdp.py
    resourcesPerNode:
      limits:
        nvidia.com/gpu: "8"
      requests:
        nvidia.com/gpu: "8"
EOF
```
* Placement Group (ê°€ìš© ì˜ì—­ ì§€ì •):
nodeSelectorì— topology.kubernetes.io/zoneì„ ëª…ì‹œí•˜ë©´, ë¶„ì‚° í•™ìŠµì‹œ ë…¸ë“œë“¤ì´ ë™ì¼í•œ AZ ë‚´ì— ë°°ì¹˜ë˜ì–´ NCCL í†µì‹  ë ˆì´í„´ì‹œê°€ í¬ê²Œ ì¤„ì–´ë“ ë‹¤.

#### 2. ì¡ ì‹¤í–‰í•˜ê¸° ####
íŠ¸ë ˆì´ë‹ ì‘ì—…ì„ ì‹œì‘í•˜ê³  ë¡œê·¸ë¥¼ í™•ì¸í•œë‹¤. 
```
kubectl apply -f t5-large.yaml

kubectl get trainjob

kubectl get pods

kubectl logs -f -l trainjob-name=t5-large
```
* Job ì‚­ì œ
```
kubectl delete trainjob t5-large
``` 


#### 3. ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥í•˜ê¸° ####
ë³¸ ì›Œí¬ì‚½ì—ì„œëŠ” ì¹´íœí„°ë¥¼ ì´ìš©í•˜ì—¬ GPU ë…¸ë“œë¥¼ í”„ë¡œë¹„ì €ë‹ í•˜ë¯€ë¡œ, íŠ¸ë ˆì´ë‹ ì¡ì„ ì‹¤í–‰ í›„ GPU ë…¸ë“œê°€ í”„ë¡œë¹„ì €ë‹ ë ë•Œ ê¹Œì§€ 1ë¶„ ì´ìƒì˜ ì‹œê°„ì´ ì†Œìš”ëœë‹¤. ì•„ë˜ ëª…ë ¹ì–´ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì— ì¡°ì¸ëœ ë…¸ë“œ ì •ë³´ë¥¼ ì¶œë ¥í•˜ëŠ” ëª…ë ¹ì–´ì´ë‹¤.
```
kubectl get nodes -o custom-columns="NAME:.metadata.name, \
   INSTANCE:.metadata.labels['node\.kubernetes\.io/instance-type'], \
   ARCH:.status.nodeInfo.architecture, \
   OS:.status.nodeInfo.osImage, \
   GPU:.status.capacity['nvidia\.com/gpu']"
```
[ê²°ê³¼]
```
NAME                                                INSTANCE       ARCH       OS                             GPU
ip-10-0-4-115.ap-northeast-2.compute.internal   c7g.2xlarge    arm64      Amazon Linux 2023.9.20251208   <none>
ip-10-0-4-210.ap-northeast-2.compute.internal   g6e.48xlarge   amd64      Amazon Linux 2023.9.20251208   8
ip-10-0-4-89.ap-northeast-2.compute.internal    g6e.48xlarge   amd64      Amazon Linux 2023.9.20251208   8
ip-10-0-6-164.ap-northeast-2.compute.internal   c6i.2xlarge    amd64      Amazon Linux 2023.9.20251208   <none>
```

## ì¥ì•  ë°œìƒ ì‹œ ë³µêµ¬ í”„ë¡œì„¸ìŠ¤ ##
ë…¸ë“œ 1ê°œê°€ ì£½ì—ˆì„ ë•Œ, ì¼ë°˜ì ì¸ NCCL í›ˆë ¨ê³¼ ë‹¬ë¦¬ torchrunì€ ë‹¤ìŒê³¼ ê°™ì´ í–‰ë™í•©ë‹ˆë‹¤.

* ì¥ì•  ê°ì§€: íŠ¹ì • Podê°€ ì£½ìœ¼ë©´ NCCL í†µì‹ ì´ ê¹¨ì§‘ë‹ˆë‹¤. ì´ë•Œ ì‚´ì•„ìˆëŠ” ë‚˜ë¨¸ì§€ Podì˜ torchrun í”„ë¡œì„¸ìŠ¤ê°€ ì´ë¥¼ ê°ì§€í•˜ê³  ìì‹ ì˜ ë¡œì»¬ í”„ë¡œì„¸ìŠ¤ë“¤ì„ ëª¨ë‘ ì¢…ë£Œ(Terminate)ì‹œí‚µë‹ˆë‹¤. (ì „ì²´ ì‘ì—…ì€ ì ì‹œ ë©ˆì¶¥ë‹ˆë‹¤.)
* ì¿ ë²„ë„¤í‹°ìŠ¤ ì¬ìŠ¤ì¼€ì¤„ë§: ì¿ ë²„ë„¤í‹°ìŠ¤ì˜ Job ì»¨íŠ¸ë¡¤ëŸ¬ë‚˜ ReplicaSetì´ ì£½ì€ Podë¥¼ ê°ì§€í•˜ê³ , ìƒˆë¡œìš´ Podë¥¼ ìë™ìœ¼ë¡œ ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤.
* ìƒˆë¡œìš´ ë‘ë°ë¶€: ìƒˆë¡œ ëœ¬ Podì™€ ê¸°ì¡´ì— ì‚´ì•„ìˆë˜ Podë“¤ì´ ë‹¤ì‹œ ë‘ë°ë¶€ ì„œë²„ì— ëª¨ì…ë‹ˆë‹¤.
* World ì¬êµ¬ì„±: ë‘ë°ë¶€ ì„œë²„ëŠ” "ì, ë‹¤ì‹œ 8ëª…ì´ ëª¨ì˜€ìœ¼ë‹ˆ ìƒˆë¡œ ì‹œì‘í•˜ì"ë¼ê³  ì‹ í˜¸ë¥¼ ë³´ëƒ…ë‹ˆë‹¤. ì´ë•Œ ë°”ë€ IP ì •ë³´ ë“±ì„ NCCLì— ë‹¤ì‹œ ì „íŒŒí•˜ì—¬ í†µì‹  ê·¸ë£¹ì„ ì¬í˜•ì„±(Re-init)í•©ë‹ˆë‹¤.
* í•™ìŠµ ì¬ê°œ: ê°œë°œìê°€ ì§  ì½”ë“œ ë‚´ì˜ load_checkpoint ë¡œì§ì— ì˜í•´ ê³µìœ  ìŠ¤í† ë¦¬ì§€ì—ì„œ ë§ˆì§€ë§‰ ìƒíƒœë¥¼ ë¶ˆëŸ¬ì™€ í•™ìŠµì„ ì´ì–´ê°‘ë‹ˆë‹¤.

#### ìš”ì•½: ë§ˆìŠ¤í„° íŒŒë“œ ì¬ì‹œì‘ ì‹œ ì‹œë‚˜ë¦¬ì˜¤ ####
* Operatorê°€ íŒŒë“œ ì¬ì‚´ë¦¼ (IPê°€ ë°”ë€Œì–´ë„ ì„œë¹„ìŠ¤ ì´ë¦„ìœ¼ë¡œ ì—°ê²° ìœ ì§€).
* PyTorch Elasticì´ ë‘ë°ë·° ê´‘ì¥ì„ ìƒˆë¡œ ê°œì„¤.
* ëª¨ë“  ì›Œì»¤ê°€ ë‹¤ì‹œ ëª¨ì—¬ì„œ ê·¸ë£¹ êµ¬ì„± (ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘).
* (ì¤‘ìš”) ì½”ë“œì— ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ë¡œì§ì´ ìˆë‹¤ë©´ ëŠê¸´ ì§€ì ë¶€í„° í•™ìŠµ ì¬ê°œ, ì—†ë‹¤ë©´ 0 ì—í­ë¶€í„° ë‹¤ì‹œ ì‹œì‘.

## ë‘ë°ë·° í¬ì¸íŠ¸ ##
* c10d (ê¶Œì¥): ì¶”ê°€ ì¸í”„ë¼ê°€ í•„ìš” ì—†ì–´ ê°€ì¥ ê°€ë³ìŠµë‹ˆë‹¤. í¬ë“œê°€ ì¬ì‹œì‘ë˜ì–´ë„ ì¿ ë²„ë„¤í‹°ìŠ¤ ì„œë¹„ìŠ¤ ì´ë¦„ì€ ìœ ì§€ë˜ë¯€ë¡œ torchrunì´ ë‹¤ì‹œ ë‘ë°ë·°í•˜ëŠ” ë° ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.
* etcd: ìˆ˜ë°± ê°œ ì´ìƒì˜ ë…¸ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ëŒ€ê·œëª¨ í´ëŸ¬ìŠ¤í„°ì—ì„œ ë‘ë°ë·°ì˜ ì•ˆì •ì„±ì„ ê·¹í•œìœ¼ë¡œ ë†’ì—¬ì•¼ í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì¼ë°˜ì ì¸ 5~10ê°œ ë…¸ë“œ ê·œëª¨ì—ì„œëŠ” c10dë¡œë„ ì¶©ë¶„í•©ë‹ˆë‹¤.





--------------------

## ì²´í¬í¬ì¸íŠ¸ ##
ëª¨ë“  ë…¸ë“œê°€ ìµœì‹  ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì— ì ‘ê·¼í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ í˜„ì—…ì—ì„œëŠ” í¬ê²Œ ë‘ ê°€ì§€ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
#### 1. ê³µìœ  ìŠ¤í† ë¦¬ì§€ ì‚¬ìš© (ê°€ì¥ ê¶Œì¥ë¨) ####
ëª¨ë“  ë…¸ë“œê°€ NFS, AWS FSx, Google Cloud Filestoreì™€ ê°™ì€ ê³µìœ  ë„¤íŠ¸ì›Œí¬ ìŠ¤í† ë¦¬ì§€ë¥¼ ë™ì¼í•œ ê²½ë¡œì— ë§ˆìš´íŠ¸í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
* ì¥ì : íŠ¹ì • ë…¸ë“œê°€ ì™„ì „íˆ ì‚¬ë¼ì ¸ë„ ë°ì´í„°ê°€ ì•ˆì „í•˜ë©°, ëª¨ë“  ë…¸ë“œê°€ ê°™ì€ ê²½ë¡œ(/mnt/nfs/checkpoint.pt)ë¥¼ ë°”ë¼ë³´ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.
* ë°©ì‹: 0ë²ˆ ë§ˆìŠ¤í„° ë…¸ë“œê°€ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•˜ë©´ ë‚˜ë¨¸ì§€ ë…¸ë“œë“¤ì´ ì¬ì‹œì‘ ì‹œ í•´ë‹¹ íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.

#### 2. ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ + ë³µì œ ####
ê° ë…¸ë“œì˜ ë¡œì»¬ ë””ìŠ¤í¬(SSD)ì— ì €ì¥í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
* ë‹¨ì : ë…¸ë“œ ìì²´ê°€ ë¬¼ë¦¬ì ìœ¼ë¡œ ê³ ì¥ ë‚˜ë©´ í•´ë‹¹ ë…¸ë“œì— ìˆë˜ ì²´í¬í¬ì¸íŠ¸ëŠ” ìœ ì‹¤ë©ë‹ˆë‹¤.
* ë°©ì‹: ì´ë¥¼ í•´ê²°í•˜ë ¤ë©´ í•™ìŠµ ì¤‘ ì£¼ê¸°ì ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ë¥¼ S3 ê°™ì€ í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ë¡œ ì—…ë¡œë“œí•˜ê±°ë‚˜, ëª¨ë“  ë…¸ë“œê°€ ê°ì ìê¸° ë””ìŠ¤í¬ì— ë™ì¼í•œ ë³µì‚¬ë³¸ì„ ì €ì¥í•˜ë„ë¡ ì„¤ê³„í•´ì•¼ í•©ë‹ˆë‹¤.

#### ğŸ’¡ torchrun ì¬ì‹œì‘ ì‹œ ì½”ë“œ êµ¬í˜„ í•µì‹¬ ####
torchrunì€ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¤ì‹œ ë„ì›Œì¤„ ë¿, ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì½”ë“œëŠ” ì§ì ‘ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ë³´í†µ ë‹¤ìŒê³¼ ê°™ì€ ë¡œì§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
```
import torch
import os

def main():
    # 1. ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì„¤ì • (ê³µìœ  ìŠ¤í† ë¦¬ì§€ ê¶Œì¥)
    ckpt_path = "/shared/storage/model_latest.pt"

    # 2. ë§Œì•½ ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ê°€ ìˆë‹¤ë©´ ë¡œë“œ
    if os.path.exists(ckpt_path):
        checkpoint = torch.load(ckpt_path, map_location='cpu')
        model.load_state_dict(checkpoint['model'])
        optimizer.load_state_dict(checkpoint['optimizer'])
        start_epoch = checkpoint['epoch']
        print(f"Resuming from epoch {start_epoch}")
    
    # 3. í•™ìŠµ ë£¨í”„ ì¤‘ ì£¼ê¸°ì  ì €ì¥ (Rank 0ë²ˆë§Œ ì €ì¥)
    if dist.get_rank() == 0:
        torch.save({...}, ckpt_path)
```
* ê³µìœ  ì €ì¥ì†Œ(NFS ë“±)ë¥¼ ì“°ëŠ” ê²ƒì´ ê°€ì¥ ì•ˆì „í•˜ê³  í¸ë¦¬í•©ë‹ˆë‹¤. 
* ë…¸ë“œê°€ ì¬ì‹œì‘ë  ë•Œ ìë™ìœ¼ë¡œ ckpt_pathë¥¼ í™•ì¸í•˜ì—¬ load_state_dictë¥¼ ìˆ˜í–‰í•˜ëŠ” ë¡œì§ì´ ì½”ë“œì— í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
* ë§Œì•½ ê³µìœ  ì €ì¥ì†Œê°€ ì—†ë‹¤ë©´, ë…¸ë“œ ì¥ì•  ì‹œ í•´ë‹¹ ë…¸ë“œì— ìˆë˜ ë°ì´í„°ëŠ” ëª» ì“°ê²Œ ë˜ë¯€ë¡œ ì™¸ë¶€ í´ë¼ìš°ë“œ ì €ì¥ì†Œ(S3 ë“±)ì— ë°±ì—…í•˜ëŠ” ì ˆì°¨ê°€ í•„ìš”í•©ë‹ˆë‹¤.


## ë ˆí¼ëŸ°ìŠ¤ ##

* https://github.com/kubeflow/trainer
* https://www.kubeflow.org/docs/components/trainer/operator-guides/migration/
* https://blog.kubeflow.org/trainer/intro/
