## [νΈλ μ΄λ‹ μ¤νΌλ μ΄ν„°(V2) μ„¤μΉ](https://www.kubeflow.org/docs/components/trainer/operator-guides/installation/) ##

V2 λ²„μ „μ νλΈ ν”λ΅μ° νΈλ μ΄λ‹ μ¤νΌλ μ΄ν„°μ™€ λ°ν„°μ„ μ„¤μΉν•λ‹¤. 
```
sudo dnf install git -y

export VERSION=v2.1.0
kubectl apply --server-side -k "https://github.com/kubeflow/trainer.git/manifests/overlays/manager?ref=${VERSION}"
kubectl apply --server-side -k "https://github.com/kubeflow/trainer.git/manifests/overlays/runtimes?ref=${VERSION}"

kubectl get pods -n kubeflow-system
kubectl get clustertrainingruntimes

```
[κ²°κ³Ό]
```
NAME                                                   READY   STATUS    RESTARTS   AGE
jobset-controller-manager-58555b47c7-ltrck             1/1     Running   0          2m55s
kubeflow-trainer-controller-manager-5b7b978fbf-r24kr   1/1     Running   0          2m55s

NAME                     AGE
deepspeed-distributed    114s
mlx-distributed          114s
torch-distributed        114s
torchtune-llama3.2-1b    114s
torchtune-llama3.2-3b    114s
torchtune-qwen2.5-1.5b   114s
```

## CRD μ΅°ν ##
```
kubectl explain trainjob.spec
kubectl explain trainjob.spec.podTemplateOverrides.spec
```


## νΈλ μ΄λ‹ μ‘μ—… μ‹¤ν–‰ ##
TrainJob μ¤νΌλ μ΄ν„°λ” backoffLimit λΌλ” ν•„λ“λ¥Ό μ΄μ©ν•μ—¬ μ‘μ—… λ³µκµ¬ λ§¤μ»¤λ‹μ¦μ„ μ κ³µν•λ‹¤. μ‘μ—…μ΄ μ‹¤ν¨ ν–μ„λ• λ‹¤μ‹ μ‹μ‘ν•λ” κΈ°λ¥μΌλ΅, μ΄ μμ μ—μ„λ” 3λ²κΉμ§€ νΈλ μ΄λ‹ μ‘μ—…μ„ μ¬ μ‹μ‘ ν•λ„λ΅ μ„¤μ • ν•μ€λ‹¤.  
```
cat <<EOF > t5-large.yaml
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  name: t5-large
spec:
  backoffLimit: 3                             # μ‘μ—… μ‹¤ν¨μ‹ μ¬μ‹λ„ νμ
  restartPolicy: OnFailure

  podTemplateOverrides:
    - targetJobs:
        name: trainer
      spec:
        nodeSelector:
          node.kubernetes.io/instance-type: g6e.48xlarge
          topology.kubernetes.io/zone: ap-northeast-2                # νΉμ • κ°€μ© μμ—­(AZ) λ‚΄ λ°°μΉλ¥Ό κ°•μ ν•μ—¬ λ…Έλ“ κ°„ ν†µμ‹  μ§€μ—°μ„ μµμ†ν™” 

  runtimeRef:
    name: torch-distributed                   # torch λ¶„μ‚° λ°±μ—”λ“ μ‚¬μ© (κ΄€λ ¨ νμ΄μ¬ ν¨ν‚¤μ§€ λ¬¶μ)
  trainer:
    numNodes: 2                            # λ…Έλ“μ μ„¤μ •
    numProcPerNode: auto                   # λ…Έλ“λ³„ ν”„λ΅μ„Έμ¤ κ°―μ                                                                               
    image: public.ecr.aws/deep-learning-containers/pytorch-training:2.8.0-gpu-py312-cu129-ubuntu22.04-ec2-v1.0
    command: |
      git clone https://github.com/gnosia93/training-on-eks /workspace/code
      cd /workspace/code/samples/fsdp
      echo "working directory: "$(pwd)
      pip install -r requirements.txt
      torchrun --nproc_per_node 8 --rdzv_id=elastic-job --rdzv_backend=c10d t5-fsdp.py
    resourcesPerNode:
      limits:
        nvidia.com: "8"
      requests:
        nvidia.com: "8"
EOF
```
νΈλ μ΄λ‹ μ‘μ—…μ„ μ‹μ‘ν•κ³  λ΅κ·Έλ¥Ό ν™•μΈν•λ‹¤. 
```
kubectl apply -f t5-large.yaml

kubectl logs -f -l trainjob-name=t5-large
```

* Placement Group (κ°€μ© μμ—­ μ§€μ •):
nodeSelectorμ— topology.kubernetes.io/zoneμ„ λ…μ‹ν•λ©΄, λ¶„μ‚° ν•™μµμ— μ°Έμ—¬ν•λ” λ…Έλ“λ“¤μ΄ λ™μΌν• λ°μ΄ν„° μ„Όν„° λ‚΄μ— λ°°μΉλμ–΄ NCCL ν†µμ‹  λ μ΄ν„΄μ‹κ°€ ν¬κ² μ¤„μ–΄λ“­λ‹λ‹¤.
* Scheduling Policy (Gang Scheduling):
schedulingPolicyλ¥Ό μ‚¬μ©ν•λ©΄ 2κ°μ λ…Έλ“κ°€ λ™μ‹μ— ν• λ‹Ήλ  λ•λ§ ν•™μµμ„ μ‹μ‘ν•©λ‹λ‹¤. μ΄λ” ν•λ‚λ” ν™•λ³΄λκ³  ν•λ‚λ” λ€κΈ° μƒνƒμΌ λ• λ°μƒν•λ” μμ› λ‚­λΉ„μ™€ ν†µμ‹  λΉ„ν¨μ¨μ„ λ°©μ§€ν•©λ‹λ‹¤.

## μ¥μ•  λ°μƒ μ‹ λ³µκµ¬ ν”„λ΅μ„Έμ¤ ##
λ…Έλ“ 1κ°κ°€ μ£½μ—μ„ λ•, μΌλ°μ μΈ NCCL ν›λ ¨κ³Ό λ‹¬λ¦¬ torchrunμ€ λ‹¤μκ³Ό κ°™μ΄ ν–‰λ™ν•©λ‹λ‹¤.

* μ¥μ•  κ°μ§€: νΉμ • Podκ°€ μ£½μΌλ©΄ NCCL ν†µμ‹ μ΄ κΉ¨μ§‘λ‹λ‹¤. μ΄λ• μ‚΄μ•„μλ” λ‚λ¨Έμ§€ Podμ torchrun ν”„λ΅μ„Έμ¤κ°€ μ΄λ¥Ό κ°μ§€ν•κ³  μμ‹ μ λ΅μ»¬ ν”„λ΅μ„Έμ¤λ“¤μ„ λ¨λ‘ μΆ…λ£(Terminate)μ‹ν‚µλ‹λ‹¤. (μ „μ²΄ μ‘μ—…μ€ μ μ‹ λ©μ¶¥λ‹λ‹¤.)
* μΏ λ²„λ„¤ν‹°μ¤ μ¬μ¤μΌ€μ¤„λ§: μΏ λ²„λ„¤ν‹°μ¤μ Job μ»¨νΈλ΅¤λ¬λ‚ ReplicaSetμ΄ μ£½μ€ Podλ¥Ό κ°μ§€ν•κ³ , μƒλ΅μ΄ Podλ¥Ό μλ™μΌλ΅ λ‹¤μ‹ μƒμ„±ν•©λ‹λ‹¤.
* μƒλ΅μ΄ λ‘λ°λ¶€: μƒλ΅ λ¬ Podμ™€ κΈ°μ΅΄μ— μ‚΄μ•„μλ Podλ“¤μ΄ λ‹¤μ‹ λ‘λ°λ¶€ μ„λ²„μ— λ¨μ…λ‹λ‹¤.
* World μ¬κµ¬μ„±: λ‘λ°λ¶€ μ„λ²„λ” "μ, λ‹¤μ‹ 8λ…μ΄ λ¨μ€μΌλ‹ μƒλ΅ μ‹μ‘ν•μ"λΌκ³  μ‹ νΈλ¥Ό λ³΄λƒ…λ‹λ‹¤. μ΄λ• λ°”λ€ IP μ •λ³΄ λ“±μ„ NCCLμ— λ‹¤μ‹ μ „νν•μ—¬ ν†µμ‹  κ·Έλ£Ήμ„ μ¬ν•μ„±(Re-init)ν•©λ‹λ‹¤.
* ν•™μµ μ¬κ°: κ°λ°μκ°€ μ§  μ½”λ“ λ‚΄μ load_checkpoint λ΅μ§μ— μν•΄ κ³µμ  μ¤ν† λ¦¬μ§€μ—μ„ λ§μ§€λ§‰ μƒνƒλ¥Ό λ¶λ¬μ™€ ν•™μµμ„ μ΄μ–΄κ°‘λ‹λ‹¤.

#### μ”μ•½: λ§μ¤ν„° νλ“ μ¬μ‹μ‘ μ‹ μ‹λ‚λ¦¬μ¤ ####
* Operatorκ°€ νλ“ μ¬μ‚΄λ¦Ό (IPκ°€ λ°”λ€μ–΄λ„ μ„λΉ„μ¤ μ΄λ¦„μΌλ΅ μ—°κ²° μ μ§€).
* PyTorch Elasticμ΄ λ‘λ°λ·° κ΄‘μ¥μ„ μƒλ΅ κ°μ„¤.
* λ¨λ“  μ›μ»¤κ°€ λ‹¤μ‹ λ¨μ—¬μ„ κ·Έλ£Ή κµ¬μ„± (μ²μλ¶€ν„° λ‹¤μ‹ μ‹μ‘).
* (μ¤‘μ”) μ½”λ“μ— μ²΄ν¬ν¬μΈνΈ λ΅λ“ λ΅μ§μ΄ μλ‹¤λ©΄ λκΈ΄ μ§€μ λ¶€ν„° ν•™μµ μ¬κ°, μ—†λ‹¤λ©΄ 0 μ—ν­λ¶€ν„° λ‹¤μ‹ μ‹μ‘.

## λ‘λ°λ·° ν¬μΈνΈ ##
* c10d (κ¶μ¥): μ¶”κ°€ μΈν”„λΌκ°€ ν•„μ” μ—†μ–΄ κ°€μ¥ κ°€λ³μµλ‹λ‹¤. ν¬λ“κ°€ μ¬μ‹μ‘λμ–΄λ„ μΏ λ²„λ„¤ν‹°μ¤ μ„λΉ„μ¤ μ΄λ¦„μ€ μ μ§€λλ―€λ΅ torchrunμ΄ λ‹¤μ‹ λ‘λ°λ·°ν•λ” λ° λ¬Έμ κ°€ μ—†μµλ‹λ‹¤.
* etcd: μλ°± κ° μ΄μƒμ λ…Έλ“λ¥Ό μ‚¬μ©ν•λ” λ€κ·λ¨ ν΄λ¬μ¤ν„°μ—μ„ λ‘λ°λ·°μ μ•μ •μ„±μ„ κ·Ήν•μΌλ΅ λ†’μ—¬μ•Ό ν•  λ• μ‚¬μ©ν•©λ‹λ‹¤. μΌλ°μ μΈ 5~10κ° λ…Έλ“ κ·λ¨μ—μ„λ” c10dλ΅λ„ μ¶©λ¶„ν•©λ‹λ‹¤.





--------------------

## μ²΄ν¬ν¬μΈνΈ ##
λ¨λ“  λ…Έλ“κ°€ μµμ‹  μ²΄ν¬ν¬μΈνΈ νμΌμ— μ ‘κ·Όν•  μ μμ–΄μ•Ό ν•©λ‹λ‹¤. μ΄λ¥Ό μ„ν•΄ ν„μ—…μ—μ„λ” ν¬κ² λ‘ κ°€μ§€ λ°©λ²•μ„ μ‚¬μ©ν•©λ‹λ‹¤.
#### 1. κ³µμ  μ¤ν† λ¦¬μ§€ μ‚¬μ© (κ°€μ¥ κ¶μ¥λ¨) ####
λ¨λ“  λ…Έλ“κ°€ NFS, AWS FSx, Google Cloud Filestoreμ™€ κ°™μ€ κ³µμ  λ„¤νΈμ›ν¬ μ¤ν† λ¦¬μ§€λ¥Ό λ™μΌν• κ²½λ΅μ— λ§μ΄νΈν•λ” λ°©μ‹μ…λ‹λ‹¤.
* μ¥μ : νΉμ • λ…Έλ“κ°€ μ™„μ „ν μ‚¬λΌμ Έλ„ λ°μ΄ν„°κ°€ μ•μ „ν•λ©°, λ¨λ“  λ…Έλ“κ°€ κ°™μ€ κ²½λ΅(/mnt/nfs/checkpoint.pt)λ¥Ό λ°”λΌλ³΄κΈ°λ§ ν•λ©΄ λ©λ‹λ‹¤.
* λ°©μ‹: 0λ² λ§μ¤ν„° λ…Έλ“κ°€ μ²΄ν¬ν¬μΈνΈλ¥Ό μ €μ¥ν•λ©΄ λ‚λ¨Έμ§€ λ…Έλ“λ“¤μ΄ μ¬μ‹μ‘ μ‹ ν•΄λ‹Ή νμΌμ„ μ½μ–΄μµλ‹λ‹¤.

#### 2. λ΅μ»¬ μ¤ν† λ¦¬μ§€ + λ³µμ  ####
κ° λ…Έλ“μ λ΅μ»¬ λ””μ¤ν¬(SSD)μ— μ €μ¥ν•λ” λ°©μ‹μ…λ‹λ‹¤.
* λ‹¨μ : λ…Έλ“ μμ²΄κ°€ λ¬Όλ¦¬μ μΌλ΅ κ³ μ¥ λ‚λ©΄ ν•΄λ‹Ή λ…Έλ“μ— μλ μ²΄ν¬ν¬μΈνΈλ” μ μ‹¤λ©λ‹λ‹¤.
* λ°©μ‹: μ΄λ¥Ό ν•΄κ²°ν•λ ¤λ©΄ ν•™μµ μ¤‘ μ£ΌκΈ°μ μΌλ΅ μ²΄ν¬ν¬μΈνΈλ¥Ό S3 κ°™μ€ ν΄λΌμ°λ“ μ¤ν† λ¦¬μ§€λ΅ μ—…λ΅λ“ν•κ±°λ‚, λ¨λ“  λ…Έλ“κ°€ κ°μ μκΈ° λ””μ¤ν¬μ— λ™μΌν• λ³µμ‚¬λ³Έμ„ μ €μ¥ν•λ„λ΅ μ„¤κ³„ν•΄μ•Ό ν•©λ‹λ‹¤.

#### π’΅ torchrun μ¬μ‹μ‘ μ‹ μ½”λ“ κµ¬ν„ ν•µμ‹¬ ####
torchrunμ€ ν”„λ΅μ„Έμ¤λ¥Ό λ‹¤μ‹ λ„μ›μ¤„ λΏ, μ²΄ν¬ν¬μΈνΈλ¥Ό λ¶λ¬μ¤λ” μ½”λ“λ” μ§μ ‘ μ‘μ„±ν•΄μ•Ό ν•©λ‹λ‹¤. λ³΄ν†µ λ‹¤μκ³Ό κ°™μ€ λ΅μ§μ„ μ‚¬μ©ν•©λ‹λ‹¤.
```
import torch
import os

def main():
    # 1. μ²΄ν¬ν¬μΈνΈ κ²½λ΅ μ„¤μ • (κ³µμ  μ¤ν† λ¦¬μ§€ κ¶μ¥)
    ckpt_path = "/shared/storage/model_latest.pt"

    # 2. λ§μ•½ κΈ°μ΅΄ μ²΄ν¬ν¬μΈνΈκ°€ μλ‹¤λ©΄ λ΅λ“
    if os.path.exists(ckpt_path):
        checkpoint = torch.load(ckpt_path, map_location='cpu')
        model.load_state_dict(checkpoint['model'])
        optimizer.load_state_dict(checkpoint['optimizer'])
        start_epoch = checkpoint['epoch']
        print(f"Resuming from epoch {start_epoch}")
    
    # 3. ν•™μµ λ£¨ν”„ μ¤‘ μ£ΌκΈ°μ  μ €μ¥ (Rank 0λ²λ§ μ €μ¥)
    if dist.get_rank() == 0:
        torch.save({...}, ckpt_path)
```
* κ³µμ  μ €μ¥μ†(NFS λ“±)λ¥Ό μ“°λ” κ²ƒμ΄ κ°€μ¥ μ•μ „ν•κ³  νΈλ¦¬ν•©λ‹λ‹¤. 
* λ…Έλ“κ°€ μ¬μ‹μ‘λ  λ• μλ™μΌλ΅ ckpt_pathλ¥Ό ν™•μΈν•μ—¬ load_state_dictλ¥Ό μν–‰ν•λ” λ΅μ§μ΄ μ½”λ“μ— ν¬ν•¨λμ–΄μ•Ό ν•©λ‹λ‹¤.
* λ§μ•½ κ³µμ  μ €μ¥μ†κ°€ μ—†λ‹¤λ©΄, λ…Έλ“ μ¥μ•  μ‹ ν•΄λ‹Ή λ…Έλ“μ— μλ λ°μ΄ν„°λ” λ» μ“°κ² λλ―€λ΅ μ™Έλ¶€ ν΄λΌμ°λ“ μ €μ¥μ†(S3 λ“±)μ— λ°±μ—…ν•λ” μ μ°¨κ°€ ν•„μ”ν•©λ‹λ‹¤.


## λ νΌλ°μ¤ ##

* https://github.com/kubeflow/trainer
* https://www.kubeflow.org/docs/components/trainer/operator-guides/migration/
* https://blog.kubeflow.org/trainer/intro/
