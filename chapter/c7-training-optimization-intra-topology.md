***ì´ ì±•í„°ëŠ” GPU ê°„ì˜ ì¸í„°ì»¤ë„¥íŠ¸ í†µì‹  ë§¤ì»¤ë‹ˆì¦˜ì„ ë‹¤ë£¨ëŠ” ì´ë¡  íŒŒíŠ¸ì´ë‹¤. ì‹¤ìŠµìš© ìŠ¤í¬ë¦½íŠ¸ë‚˜ í…ŒìŠ¤íŠ¸ í™˜ê²½ì€ ì œê³µí•˜ì§€ ì•ŠëŠ”ë‹¤.***  

## GPU í† í´ë¡œì§€ ##
GPU ì™€ GPU ê°„ì˜ ë°ì´í„°ë¥¼ ì£¼ê³  ë°›ì€ ë°©ì‹ì—ëŠ” ì•„ë˜ì™€ ê°™ì´ 4ê°€ì§€ íƒ€ì…ì´ ìˆë‹¤. ì´ì¤‘ P2P ë°©ì‹ì€ CPU ì˜ ê°œì… ì—†ì´ GPU ê°€ ì„œë¡œì˜ ë©”ëª¨ë¦¬(VRAM)ì— ì§ì ‘ ì ‘ê·¼í•˜ì—¬ ë°ì´í„°ë¥¼ ì£¼ê³ ë°›ëŠ” ê¸°ìˆ ì´ë‹¤. ì´ì— ë¹„í•´ SHM ë°©ì‹ì€ CPU ê°œì…ì´ í•„ìš”í•œ 2íšŒì— ê±¸ì¹œ ë©”ëª¨ë¦¬ ë³µì‚¬ ê³¼ì •(GPU->RAM->GPU)ê³¼ ë©”ëª¨ë¦¬ ëŒ€ì—­í­ ë³‘ëª©ìœ¼ë¡œ ì¸í•´ í†µì‹  ì„±ëŠ¥ì´ ì €í•˜ëœë‹¤. NCCLì€ GPU ê°„ ë°ì´í„° ì „ì†¡ ì‹œ ì§€ì—° ì‹œê°„ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ CPU ê°œì… ì—†ì´ GPU ë©”ëª¨ë¦¬ì— ì§ì ‘ ì ‘ê·¼í•˜ëŠ” P2P(Peer-to-Peer) í†µì‹  ì•„í‚¤í…ì²˜ë¥¼ ìµœìš°ì„  ìˆœìœ„ë¡œ í• ë‹¹í•œë‹¤. ë§Œì•½ í•˜ë“œì›¨ì–´ í† í´ë¡œì§€ë‚˜ ì‹œìŠ¤í…œ ì œì•½(í•˜ì´í¼ë°”ì´ì € ì„¤ì •)ìœ¼ë¡œ ì¸í•´ Direct Accessê°€ ì°¨ë‹¨ë  ê²½ìš°, ì‹œìŠ¤í…œ ë©”ì¸ ë©”ëª¨ë¦¬ë¥¼ ì¤‘ê°„ ë²„í¼ë¡œ í™œìš©í•˜ëŠ” SHM(Shared Memory) í”„ë¡œí† ì½œì„ ì°¨ì„ ì±…(Fallback)ìœ¼ë¡œ ì±„íƒí•˜ì—¬ í†µì‹  ê°€ìš©ì„±ì„ ë³´ì¥í•˜ê²Œ ëœë‹¤. GPUDirect RDMA ëŠ” ì„œë¡œ ë‹¤ë¥¸ ë…¸ë“œì˜ GPU ê°„ì˜ í†µì‹ ìœ¼ë¡œ RoCE, IB, EFA ë“±ì„ ì‚¬ìš©í•˜ê²Œ ëœë‹¤.  

* GPU P2P 
  * NVLink / NVSwitch
  * PCIe P2P (Direct Access) - ë°ì´í„°ê°€ CPU(Host RAM)ë¥¼ ê±°ì¹˜ì§€ ì•Šê³  PCIe ë²„ìŠ¤/ìŠ¤ìœ„ì¹˜ë¥¼ í†µí•´ ë°”ë¡œ ì˜† GPUë¡œ ì´ë™í•˜ëŠ” ë°©ì‹
     * ë™ì‘ ë°©ì‹: GPU A ë©”ëª¨ë¦¬ â†’ PCIe Switch â†’ GPU B ë©”ëª¨ë¦¬.
     * ì„±ëŠ¥: SHMë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ë©°, nvidia-smi topo -m ê²°ê³¼ì—ì„œ PIX ë˜ëŠ” PXBë¡œ í‘œì‹œë  ë•Œ ì´ ë°©ì‹ì´ ì‚¬ìš©.
  * GPUDirect RDMA -  ë‹¤ë¥¸ ë…¸ë“œ GPU ê°„ì˜ í†µì‹  
* SHM (Shared Memory)
  * Host ì™€ Device ê°„ì˜ ë©”ëª¨ë¦¬ ì¹´í”¼ 2íšŒ ì´ìƒ ë°œìƒ
  * PCIe Bandwidth ë³‘ëª© / CPU ë³‘ëª© ëª¨ë‘ ë°œìƒ / PCIe ì— ì—°ê²°ëœ ë‹¤ë¥¸ ë””ë°”ì´ìŠ¤ì— ì˜í•œ PCIe ë ˆì¸(ëŒ€ì—­í­) ë¶„í•  ë° ê°ì†Œ 
  * GPU ë‚´ë¶€ ë©”ëª¨ë¦¬ ëŒ€ì—­í­ì€ ë³´í†µ ìˆ˜ TB/s ë‹¨ìœ„ì§€ë§Œ, ì´ ë°ì´í„°ê°€ ì§€ë‚˜ê°€ëŠ” PCIe í†µë¡œëŠ” ì„¸ëŒ€ì— ë”°ë¼ ìµœëŒ€ë¡œ ì¡ì•„ë„ 32GB/s(Gen4) ~ 64GB/s(Gen5) ìˆ˜ì¤€.
  * ì´ ì¢ì€ ê¸¸ì„ ë‘ ë²ˆì´ë‚˜ ì™”ë‹¤ ê°”ë‹¤ í•´ì•¼ í•˜ë‹ˆ ì†ë„ê°€ ìˆ˜ì‹­ ë°°ë¡œ ì¤„ì–´ë“œê²Œ ëœë‹¤.
    
### P2P ì§€ì› ì—¬ë¶€ í™•ì¸ ###
ì•„ë˜ëŠ” g6e.12xlarge ì˜ GPU í† í´ë¡œì§€ë¡œ NODEëŠ” CPU í†µì‹ ì„ ì˜ë¯¸í•œë‹¤.
ë°ì´í„° í†µì‹ ì‹œ PIX / PXB (PCIe Switch)ëŠ” ë©”ì¸ë³´ë“œì— ìˆëŠ” ë³„ë„ì˜ PCIe ìŠ¤ìœ„ì¹˜ ì¹©ì—ì„œ ë°ì´í„°ê°€ ìœ í„´í•˜ì—¬ ì˜† GPUë¡œ ê°„ë‹¤. ì¦‰, CPUê¹Œì§€ ì˜¬ë¼ê°€ì§€ ì•ŠëŠ”ë‹¤.
NODEì˜ PCIe ìŠ¤ìœ„ì¹˜ê°€ ì—†ì–´ì„œ ë°ì´í„°ê°€ ì¼ë‹¨ CPU ë¨¸ë¦¬(Host Bridge)ê¹Œì§€ ì˜¬ë¼ê°”ë‹¤ê°€ ë‹¤ì‹œ ë‚´ë ¤ì˜¤ëŠ” êµ¬ì¡°ì´ë‹¤.
NODEì˜ í† í´ë¡œì§€ëŠ” GPU 0 â†’ PCIe ìŠ¬ë¡¯ â†’ CPU ë‚´ë¶€ PCIe Controller A â†’ CPU ë‚´ë¶€ ì¸í„°ì»¤ë„¥íŠ¸(Mesh/Ring Bus) â†’ CPU ë‚´ë¶€ PCIe Controller B â†’ PCIe ìŠ¬ë¡¯ â†’ GPU 1 ì´ë‹¤.
```
# nvidia-smi topo -m
        GPU0    GPU1    GPU2    GPU3    CPU Affinity    NUMA Affinity   GPU NUMA ID
GPU0     X      NODE    NODE    NODE    0-47    0               N/A
GPU1    NODE     X      NODE    NODE    0-47    0               N/A
GPU2    NODE    NODE     X      NODE    0-47    0               N/A
GPU3    NODE    NODE    NODE     X      0-47    0               N/A

Legend:

  X    = Self
  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing at most a single PCIe bridge
  NV#  = Connection traversing a bonded set of # NVLinks
```

ì•„ë˜ëŠ” p4d.24xlarge ì˜ GPU í† í´ë¡œì§€ë¡œ NVLink ë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤.
```
# nvidia-smi topo -m
        GPU0    GPU1    GPU2    GPU3    GPU4    GPU5    GPU6    GPU7    CPU Affinity    NUMA Affinity   GPU NUMA ID
GPU0     X      NV12    NV12    NV12    NV12    NV12    NV12    NV12    0-23,48-71      0               N/A
GPU1    NV12     X      NV12    NV12    NV12    NV12    NV12    NV12    0-23,48-71      0               N/A
GPU2    NV12    NV12     X      NV12    NV12    NV12    NV12    NV12    0-23,48-71      0               N/A
GPU3    NV12    NV12    NV12     X      NV12    NV12    NV12    NV12    0-23,48-71      0               N/A
GPU4    NV12    NV12    NV12    NV12     X      NV12    NV12    NV12    24-47,72-95     1               N/A
GPU5    NV12    NV12    NV12    NV12    NV12     X      NV12    NV12    24-47,72-95     1               N/A
GPU6    NV12    NV12    NV12    NV12    NV12    NV12     X      NV12    24-47,72-95     1               N/A
GPU7    NV12    NV12    NV12    NV12    NV12    NV12    NV12     X      24-47,72-95     1               N/A

Legend:

  X    = Self
  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing at most a single PCIe bridge
  NV#  = Connection traversing a bonded set of # NVLinks
```
ì•„ë˜ëŠ” p5.48xlarge ì˜ GPU í† í´ë¡œì§€ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ì—¬ê¸°ì„œ NV18 ì´ë€ ë‘ GPU ì‚¬ì´ì— ì—°ê²°ëœ NVLinkì˜ ë ˆì¸ ìˆ˜ë¥¼ ì˜ë¯¸í•˜ëŠ” ê²ƒìœ¼ë¡œ ìˆ«ìê°€ ë†’ì„ìˆ˜ë¡ ëŒ€ì—­í­(ë°ì´í„° ì „ì†¡ ì†ë„)ì´ ë” ë„“ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸ í•œë‹¤.
```
# nvidia-smi topo -m
        GPU0    GPU1    GPU2    GPU3    GPU4    GPU5    GPU6    GPU7    CPU Affinity    NUMA Affinity   GPU NUMA ID
GPU0     X      NV18    NV18    NV18    NV18    NV18    NV18    NV18    0-47,96-143     0               N/A
GPU1    NV18     X      NV18    NV18    NV18    NV18    NV18    NV18    0-47,96-143     0               N/A
GPU2    NV18    NV18     X      NV18    NV18    NV18    NV18    NV18    0-47,96-143     0               N/A
GPU3    NV18    NV18    NV18     X      NV18    NV18    NV18    NV18    0-47,96-143     0               N/A
GPU4    NV18    NV18    NV18    NV18     X      NV18    NV18    NV18    48-95,144-191   1               N/A
GPU5    NV18    NV18    NV18    NV18    NV18     X      NV18    NV18    48-95,144-191   1               N/A
GPU6    NV18    NV18    NV18    NV18    NV18    NV18     X      NV18    48-95,144-191   1               N/A
GPU7    NV18    NV18    NV18    NV18    NV18    NV18    NV18     X      48-95,144-191   1               N/A

Legend:

  X    = Self
  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing at most a single PCIe bridge
  NV#  = Connection traversing a bonded set of # NVLinks
```


### ì¸í„°ì»¤ë„¥íŠ¸ íƒ€ì…ë³„ ëŒ€ì—­í­ ###
![](https://github.com/gnosia93/training-on-eks/blob/main/chapter/images/topology-througput.png)


### ì»¨í…Œì´ë„ˆ í•„ìˆ˜ ì˜µì…˜ ###

* hostIPC: true  
  ì»¨í…Œì´ë„ˆê°€ í˜¸ìŠ¤íŠ¸ì˜ IPC(Inter-Process Communication) ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ê³µìœ í•˜ê²Œ í•˜ì—¬ GPU ê°„ P2P í•¸ë“œì‰ì´í¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.
ì´ë•Œ ì£¼ì˜í•  ì ì€ í•œ ì»¨í…Œì´ë„ˆ ì•ˆì— í†µì‹ ì— í•„ìš”í•œ ëª¨ë“  GPUë¥¼ ëª°ì•„ ë„£ì–´ì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤. GPU P2PëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê°™ì€ ë©”ëª¨ë¦¬ ì£¼ì†Œ ì²´ê³„ë¥¼ ê³µìœ í•˜ëŠ” ë™ì¼ í”„ë¡œì„¸ìŠ¤ ë˜ëŠ” ê³µìœ  ë©”ëª¨ë¦¬ë¡œ ë¬¶ì¸ ê·¸ë£¹ ë‚´ì—ì„œë§Œ ì‘ë™í•˜ê¸° ë•Œë¬¸ì´ë‹¤.
  ```
  apiVersion: v1
  kind: Pod
  metadata:
    name: host-ipc-example
  spec:
    hostIPC: true  # í˜¸ìŠ¤íŠ¸ì˜ IPC ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê³µìœ  ì„¤ì •
    containers:
    - name: shared-memory-app
      image: ubuntu
      command: ["/bin/sh", "-c", "sleep 3600"]
  ```
  ì»¨í…Œì´ë„ˆ í™˜ê²½ì—ì„œ host IPC(Inter-Process Communication)ë¥¼ ì‚¬ìš©í•˜ë©´ ì»¨í…Œì´ë„ˆê°€ í˜¸ìŠ¤íŠ¸ ë¨¸ì‹ ì˜ IPC ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ê³µìœ í•˜ê²Œ ëœë‹¤. ì´ë¥¼ í†µí•´ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì˜ í”„ë¡œì„¸ìŠ¤ê°€ í˜¸ìŠ¤íŠ¸ë‚˜ ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆì˜ í”„ë¡œì„¸ìŠ¤ì™€ ê³µìœ  ë©”ëª¨ë¦¬, ì„¸ë§ˆí¬ì–´, ë©”ì‹œì§€ í ë“±ì„ í†µí•´ ì§ì ‘ í†µì‹ í•  ìˆ˜ ìˆë‹¤.

* securityContext & shareProcessNamespace
```
  securityContext:
      capabilities:
        add:
        - IPC_LOCK
      privileged: true
  shareProcessNamespace: true
```
* shareProcessNamespace: trueì˜ ì—­í• 
í•œ Pod ë‚´ì— ì—¬ëŸ¬ ì»¨í…Œì´ë„ˆê°€ ìˆì„ ë•Œ í”„ë¡œì„¸ìŠ¤ ID(PID)ë¥¼ ê³µìœ í•˜ê²Œ í•´ì¤ë‹ˆë‹¤.
ë¶„ì‚° í•™ìŠµì—ì„œëŠ” ì£¼ë¡œ ë””ë²„ê¹…ì´ë‚˜ ì‚¬ì´ë“œì¹´ ì»¨í…Œì´ë„ˆê°€ ì£¼ í•™ìŠµ ì»¨í…Œì´ë„ˆì˜ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

* ì™œ hostNetwork: trueë¥¼ ì“°ì§€ ì•Šë‚˜ìš”?
ë¬¼ë¡  hostNetwork: trueë¥¼ ì„¤ì •í•˜ë©´ ë„¤íŠ¸ì›Œí¬ ê²©ë¦¬ê°€ ì•„ì˜ˆ ì—†ì–´ì§€ë¯€ë¡œ ê°€ì¥ ë‹¨ìˆœí•˜ê³  ë¹ ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ EKS(Kubernetes) í™˜ê²½ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ë¡œ ì§€ì–‘í•©ë‹ˆë‹¤.
  * í¬íŠ¸ ì¶©ëŒ: í•œ ë…¸ë“œì— ê°™ì€ í¬íŠ¸ë¥¼ ì“°ëŠ” Podë¥¼ ë‘ ê°œ ì´ìƒ ë„ìš¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
  * ë³´ì•ˆ: ì»¨í…Œì´ë„ˆê°€ í˜¸ìŠ¤íŠ¸ì˜ ëª¨ë“  ë„¤íŠ¸ì›Œí¬ ì„œë¹„ìŠ¤ì— ì ‘ê·¼ ê°€ëŠ¥í•´ì ¸ ë³´ì•ˆìƒ ìœ„í—˜í•©ë‹ˆë‹¤.
  * ê´€ë¦¬: ì¿ ë²„ë„¤í‹°ìŠ¤ì˜ ì¥ì ì¸ ë„¤íŠ¸ì›Œí¬ ì •ì±…(Network Policy) ë“±ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ê²Œ ë©ë‹ˆë‹¤.
  * true ë¡œ ì„¤ì •í•˜ëŠ” ê²½ìš° pytrochjob / trainJob ì´ í¬íŠ¸ ì¶©ëŒë¡œ ë™ì‘í•˜ì§€ ì•ŠëŠ”ë‹¤.
    * CNI ë¥¼ vpc-cni + cillium mixed ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.. ì´ˆê¸° rdma ì´ë‹ˆì…œ ë¼ì´ì¦ˆì‹œ ì¼ë°˜ tcp/ip ë¥¼ í†µê³¼í•˜ê²Œ ë˜ê³ , ì—°ê²°ì´ ë§ºì–´ì§„ í›„ë£¨ëŠ” tcp/ip ìŠ¤íƒì„ bypass í•œë‹¤..
  * 1. [ë…¸ë“œë‹¹ íŒŒë“œ 1ê°œ] - hostNetwork: true ê°•ì œ ì ìš©
    * ë…¸ë“œ ì „ì²´ ìì›(8 GPU ë“±)ì„ íŒŒë“œ í•˜ë‚˜ê°€ ë‹¤ ì“°ëŠ” ëŒ€ê·œëª¨ í•™ìŠµì´ë¼ë©´, PyTorchJobì—ì„œë„ hostNetworkë¥¼ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í¬íŠ¸ ì¶©ëŒ ê±±ì •ì´ ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
    * ì„¤ì • ë°©ë²•: YAMLì˜ spec.template.spec ì•„ë˜ì— hostNetwork: trueë¥¼ ëª…ì‹œí•©ë‹ˆë‹¤.
    * ì£¼ì˜ì‚¬í•­: dnsPolicy: ClusterFirstWithHostNet ì„¤ì •ì„ ë°˜ë“œì‹œ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë˜ì•¼ hostNetwork ëª¨ë“œì—ì„œë„ ì¿ ë²„ë„¤í‹°ìŠ¤ ë‚´ë¶€ DNS(CoreDNS)ë¥¼ ì°¾ì•„ê°€ì„œ í—¤ë“œë¦¬ìŠ¤ ì„œë¹„ìŠ¤ ì´ë¦„ì„ í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    * ì¥ì : ê°€ì¥ ì™„ë²½í•œ RDMA ì„±ëŠ¥ì´ ë‚˜ì˜µë‹ˆë‹¤.
  * 2. [ë…¸ë“œë‹¹ íŒŒë“œ ì—¬ëŸ¬ ê°œ] - Multus CNIê°€ ìœ ì¼í•œ í‡´ë¡œ
    * ì´ ê²½ìš°ê°€ ì§„ì§œ ë¬¸ì œì…ë‹ˆë‹¤. hostNetwork: trueë¥¼ ì“°ë©´ í¬íŠ¸ê°€ ê²¹ì³ì„œ íŒŒë“œê°€ ì£½ì–´ë²„ë¦½ë‹ˆë‹¤. ì´ë•ŒëŠ” "ì œì–´ëŠ” ê°€ìƒìœ¼ë¡œ, ë°ì´í„°ëŠ” ì‹¤ë¬¼ë¡œ" ë¶„ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.
    * Multus CNI í™œìš©:
      * eth0 (ê¸°ë³¸): hostNetwork: false ìƒíƒœë¡œ ë‘¡ë‹ˆë‹¤. PyTorchJobì´ ê´€ë¦¬í•˜ëŠ” ì œì–´ íŒ¨í‚·ê³¼ í¬íŠ¸ë“¤ì€ ì—¬ê¸°ì„œ ëŒì•„ê°‘ë‹ˆë‹¤. (iptablesì˜ ê°„ì„­ì„ ë°›ì§€ë§Œ, ë°ì´í„° ì–‘ì´ ì ì–´ ê´œì°®ìŠµë‹ˆë‹¤.)
      * net1 (ì¶”ê°€): SR-IOVë¥¼ í†µí•´ H100 ì „ìš© NICì˜ ê°€ìƒ í•¨ìˆ˜(VF)ë¥¼ íŒŒë“œì— ì§ì ‘ ê½‚ì•„ì¤ë‹ˆë‹¤.
      * í•µì‹¬ ì„¤ì •: NCCLì´ eth0ê°€ ì•„ë‹Œ net1ì„ ë°ì´í„° í†µë¡œë¡œ ì“°ë„ë¡ ê°•ì œí•©ë‹ˆë‹¤   
  ```
  ì˜¨í”„ë ˆë¯¸ìŠ¤ì—ì„œ ê²ªê²Œ ë  ëŒ€í‘œì ì¸ 'ì‚½ì§ˆ' í¬ì¸íŠ¸ 3ê°€ì§€ë§Œ ìš”ì•½í•´ ë“œë¦´ê²Œìš”.
  1. "íŒŒë“œ IP = ë¬¼ë¦¬ IP"ê°€ ì•„ë‹ˆë‹¤ (Overlayì˜ ì €ì£¼)
  AWS VPC CNIëŠ” ì‹¤ì œ VPC IPë¥¼ íŒŒë“œì— ê½‚ì•„ì£¼ì§€ë§Œ, ì˜¨í”„ë ˆë¯¸ìŠ¤ ê¸°ë³¸ CNI(Calico, Flannel ë“±)ëŠ” ë³´í†µ VxLANì´ë‚˜ Geneve ê°™ì€ í„°ë„ë§ì„ ì”ë‹ˆë‹¤.
  ì‚½ì§ˆ: íŒ¨í‚·ì„ ë³´ë‚¼ ë•Œë§ˆë‹¤ ì»¤ë„ì´ íŒ¨í‚·ì„ í•œ ë²ˆ ë” ê°ì‹¸ëŠ”(Encapsulation) ì—°ì‚°ì„ í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ iptablesì™€ CPU ì˜¤ë²„í—¤ë“œê°€ í­ë°œí•˜ë©° RDMA ì„±ëŠ¥ì´ ê¹ì…ë‹ˆë‹¤.
  í•´ê²°: ì´ë¥¼ í”¼í•˜ë ¤ê³  BGP ì„¤ì •ì„ í•˜ê±°ë‚˜, ì•„ì˜ˆ L2 Direct Routing ì„¤ì •ì„ ìœ„í•´ ë„¤íŠ¸ì›Œí¬ ì¥ë¹„(ìŠ¤ìœ„ì¹˜) ì„¤ì •ê¹Œì§€ ê±´ë“œë ¤ì•¼ í•©ë‹ˆë‹¤.
  2. RDMA/RoCE v2 ì„¤ì •ì˜ ì§€ì˜¥ (Lossless Network)
  AWS EFAëŠ” ì „ìš© ë§ì´ë¼ ì‹ ê²½ ì•ˆ ì¨ë„ ë˜ì§€ë§Œ, ì˜¨í”„ë ˆë¯¸ìŠ¤ ì´ë”ë„·ì—ì„œ RDMAë¥¼ ì“°ë ¤ë©´ íŒ¨í‚· ìœ ì‹¤ì´ 0ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
  ì‚½ì§ˆ: ìŠ¤ìœ„ì¹˜ì—ì„œ PFC(Priority Flow Control)ì™€ ECN(Explicit Congestion Notification) ì„¤ì •ì„ ë…¸ë“œì™€ 1:1ë¡œ ë§ì¶°ì•¼ í•©ë‹ˆë‹¤. Mellanox RoCEv2 ê°€ì´ë“œ ì„¤ì •ì´ ì¡°ê¸ˆì´ë¼ë„ ì–´ê¸‹ë‚˜ë©´ RDMAê°€ ì¤‘ë‹¨ë˜ê³  ëŠë¦° TCPë¡œ ì „í™˜ë©ë‹ˆë‹¤.
  3. ë©€í‹° NIC êµ¬ì„± (Multus CNI)
  H100 ì„œë²„ëŠ” ë³´í†µ í›ˆë ¨ìš© NICê°€ 8ê°œ ì´ìƒ ë°•í˜€ ìˆìŠµë‹ˆë‹¤.
  ì‚½ì§ˆ: ì¿ ë²„ë„¤í‹°ìŠ¤ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ íŒŒë“œì— NICë¥¼ í•˜ë‚˜ë§Œ ì¤ë‹ˆë‹¤. 8ê°œì˜ NICë¥¼ íŒŒë“œ ì•ˆì— ë‹¤ ë„£ì–´ì£¼ë ¤ë©´ Multus CNIì™€ SR-IOV Device Pluginì„ ì§ì ‘ ì„¤ì¹˜í•˜ê³  YAMLë¡œ ì¼ì¼ì´ ë§¤í•‘í•´ì•¼ í•©ë‹ˆë‹¤.
  ğŸ’¡ í•œ ì¤„ ìš”ì•½
  "AWSëŠ” ëˆ(ë¹„ìš©)ìœ¼ë¡œ í•´ê²°í•œ ê³ ì†ë„ë¡œë¥¼ ë¹Œë ¤ì£¼ëŠ” ê²ƒì´ê³ , ì˜¨í”„ë ˆë¯¸ìŠ¤ëŠ” ê·¸ ê³ ì†ë„ë¡œë¥¼ ì§ì ‘ ì•„ìŠ¤íŒ”íŠ¸ ê¹”ê³  í‘œì§€íŒ(ì„¤ì •) ì„¸ìš°ë©° ë§Œë“¤ì–´ì•¼ í•œë‹¤"ê³  ë³´ì‹œë©´ ë©ë‹ˆë‹¤
  ``` 
* resource limit:  
  nvidia.com/gpu ë¥¼ 2ê°œ ì´ìƒ í• ë‹¹í•´ì•¼ ë‹¨ì¼ ë…¸ë“œ ë‚´ P2P í†µì‹ ì´ ê°€ëŠ¥í•˜ë‹¤

## ë©€í‹° GPU í™˜ê²½ì—ì„œì˜ Pod ë°°ì¹˜ ##

í˜„ì¬ AWS ì˜ ê°€ì† ì¸ìŠ¤í„´ìŠ¤ë“¤ì€ GPU 1, 4, 8 ê°œ íƒ€ì…ì˜ ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ ì œê³µí•˜ê³  ìˆë‹¤. í•˜ë‚˜ì˜ ë…¸ë“œì— GPUë¥¼ ì—¬ëŸ¬ê°œ ê°€ì§€ê³  ìˆëŠ” ê²½ìš° Podë¥¼ ì–´ë–¤ì‹ìœ¼ë¡œ ë°°ì¹˜í•˜ëŠ” ê²ƒì´ í†µì‹  íš¨ìœ¨ì„±ì„ ìµœëŒ€í™” í•  ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•´ì„œ ë‹¤ë£¨ê³ ì í•œë‹¤.   
ê²°ë¡  ë¶€í„° ë§í•˜ìë©´ PodëŠ” ë…¸ë“œë³„ë¡œ í•˜ë‚˜ì”© ë°°ì¹˜í•˜ëŠ” ê²ƒì´ íš¨ê³¼ì ì´ë‹¤. ì¦‰ 8ê°œì˜ GPUë¥¼ ê°€ì§€ê³  ìˆëŠ” EC2 ì¸ìŠ¤í„´ìŠ¤ì— Podë¥¼ ë°°ì¹˜í• ë•Œ 8ê°œê°€ ì•„ë‹ˆë¼ 1ê°œì˜ Podë¥¼ ë°°ì¹˜í•˜ê³ , í•´ë‹¹ Pod ë‚´ë¶€ì—ì„œ 8ê°œì˜ íŒŒì´ì¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•˜ëŠ” ê²ƒì´ í›¨ì”¬ ìœ ë¦¬í•˜ë‹¤.   
ì¼ë°˜ VM í™˜ê²½ì—ì„œ í•˜ë‚˜ì˜ ì„œë²„ê°€ ì¿ ë²„ë„¤í‹°ìŠ¤ í™˜ê²½ì—ì„œ í•˜ë‚˜ì˜ Pod ì´ê³  ì„œë¡œ ì™„ì „íˆ ë…ë¦½ì ì¸ ì¡´ì¬ë¡œ ì·¨ê¸‰ë˜ê¸° ë•Œë¬¸ì—, ì—¬ëŸ¬ Pod ê°€ ë™ì‹œì— ê°™ì€ ê³µê°„ ì¦‰ ê°™ì€ EC2 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ë”ë¼ë„ GPU / CPU / Memory ì™€ ê°™ì€ ë¦¬ì†ŒìŠ¤ë¥¼ ì™„ì „íˆ ë³„ê°œì´ë©° ê°™ì€ ê³µê°„(ì„œë²„)ì— ìˆëŠ” GPU ì¸ì§€ ì•„ë‹Œì§€ êµ¬ë³„í•˜ì§€ ëª»í•œë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì¸í•´ ê°™ì€ ì„œë²„ì—ì„œ ì‹¤í–‰ë˜ì§€ë§Œ NVLink ë‚˜ PCIe ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ í†µì‹  í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼ EFA ë˜ëŠ” ENI ë¥¼ í†µí•´ ì„œë¡œ í†µì‹  í•˜ê²Œ ëœë‹¤.   
ë¬¼ë¦¬ì ìœ¼ë¡œ ê°™ì€ ì¥ì¹˜(ì„œë²„)ì•ˆì— ìˆëŠ” GPU ë¼ë¦¬ë„ NVLink ë¡œ ì§ì ‘ ì“°ì§€ ëª»í•˜ê³  ë„¤íŠ¸ì›Œí¬ ìŠ¤íƒì„ í•œ ë²ˆ ê±°ì³ì•¼ í•˜ëŠ” ë³‘ëª©ì´ ìƒê¸¸ ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ë‹¤.

#### 1. í†µì‹  ê²½ë¡œ(Topology) ####
* (1 Pod x 8 GPU): í•˜ë‚˜ì˜ Pod(ì»¨í…Œì´ë„ˆ) ì•ˆì— GPU 8ì¥ì´ ëª¨ë‘ ë³´ì´ëŠ” êµ¬ì¡°ë¡œ, NCCLì€ ì´ë“¤ì´ ê°™ì€ ë©”ëª¨ë¦¬ ì£¼ì†Œ ê³µê°„ì— ìˆìŒì„ ì¸ì§€í•˜ê³  NVLink ë˜ëŠ” PCIe P2P(Peer-to-Peer)ë¥¼ í†µí•´ í†µì‹ í•œë‹¤.
* (8 Pod x 1 GPU): ê° íŒŒë“œëŠ” ì™„ì „íˆ ê²©ë¦¬ëœ í™˜ê²½ì—ì„œ ë™ì‘í•˜ë¯€ë¡œ ë°ì´í„°ë¥¼ ë³´ë‚¼ ë•Œ GPU 0 -> í˜¸ìŠ¤íŠ¸ ë©”ëª¨ë¦¬ -> ë„¤íŠ¸ì›Œí¬ ì¹´ë“œ(EFA/TCP) -> í˜¸ìŠ¤íŠ¸ ë©”ëª¨ë¦¬ -> GPU 1ì˜ ë³µì¡í•œ ê²½ë¡œë¥¼ ê±°ì¹˜ê²Œ ëœë‹¤. EFA ì—°ê²°ì‹œ í˜¸ìŠ¤íŠ¸ ë©”ëª¨ë¦¬ë¥¼ ê±°ì¹˜ì§€ ì•Šìœ¼ë‚˜ AWS ì˜ ê²½ìš° EC2 ì¸ìŠ¤í„´ìŠ¤ ìµœëŒ€ 4ì¥ ê¹Œì§€ì˜ EFA ë§Œ ì§€ì›í•˜ê³  ìˆì–´, 8ì¥ì˜ GPU ë¥¼ ê°€ì§„ EC2 ì¸ìŠ¤í„´ìŠ¤ì—ì„œëŠ” GPU ì™€ì˜ 1ëŒ€ 1 ë§¤í•‘ì´ ì–´ë µë‹ˆë‹¤. (ì¦‰ GPU ì…ì¥ì—ì„œ 4ì¥ë§Œ ì‚¬ìš©í•´ì•¼ í• ìˆ˜ë„)  

ì•„ë˜ëŠ” p4d.48xlarge ì¸ìŠ¤í„´ìŠ¤ì—ì„œ Pod(1 GPU /1 EFA í• ë‹¹) ë¥¼ 4ê°œ ë„ì› ì„ë•Œì˜ NCCL ë¡œê·¸ì´ë‹¤. ë™ì¼ ì„œë²„ì— ìˆëŠ” Pod ì´ì§€ë§Œ, NVLink ë¥¼ ì‚¬ìš©í•˜ì§€ ëª»í•˜ê³  
NET/Libfabric/0/GDRDMA ì¦‰ EFA ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ í†µì‹ í•˜ê³  ìˆë‹¤.   
```
df: /root/.triton/autotune: No such file or directory
llama-3-8b-node-0-0:188:188 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0,lo
llama-3-8b-node-0-0:188:188 [0] NCCL INFO Bootstrap: Using eth0:10.0.5.112<0>
llama-3-8b-node-0-0:188:188 [0] NCCL INFO cudaDriverVersion 13000
llama-3-8b-node-0-0:188:188 [0] NCCL INFO NCCL version 2.27.3+cuda12.9
llama-3-8b-node-0-0:188:188 [0] NCCL INFO Comm config Blocking set to 1
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net.so
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/Plugin: Loaded net plugin Libfabric (v10)
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v10 symbol.
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v9 symbol.
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
llama-3-8b-node-0-0:188:585 [0] NCCL INFO Successfully loaded external plugin libnccl-net.so
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.16.2
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Using Libfabric version 2.1
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Using CUDA driver version 13000 with runtime 12090
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Configuring AWS-specific options
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Setting provider_filter to efa
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Running on p4d.24xlarge platform, topology file /opt/amazon/ofi-nccl/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Internode latency set at 75.0 us
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV (platform set)
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Selected provider is efa, fabric is efa (found 1 nics)
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Creating one domain per process
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI GUID of rdmap16s27: 0000000000000000
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI GUID for dev[0]: 00000000000000000a00057000000000
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Need to force simple protocol: byte delivery ordering not supported
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Support for global registrations: false
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Adding FI_EFA_FORK_SAFE=1 to environment
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Adding NCCL_BUFFSIZE=8388608 to environment
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Adding NCCL_P2P_NET_CHUNKSIZE=524288 to environment
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Adding NCCL_PROTO=simple to environment
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Adding NCCL_TOPO_FILE=/opt/amazon/ofi-nccl/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml to environment
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI Adding NCCL_TUNER_PLUGIN=libnccl-net.so to environment
llama-3-8b-node-0-0:188:585 [0] NCCL INFO Initialized NET plugin Libfabric
llama-3-8b-node-0-0:188:585 [0] NCCL INFO Assigned NET plugin Libfabric to comm
llama-3-8b-node-0-0:188:585 [0] NCCL INFO Using network Libfabric
llama-3-8b-node-0-0:188:585 [0] NCCL INFO DMA-BUF is available on GPU device 0
llama-3-8b-node-0-0:188:585 [0] NCCL INFO ncclCommInitRankConfig comm 0x556d504b7460 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 101d0 commId 0xb079519ed44b724 - Init START
llama-3-8b-node-0-0:188:585 [0] NCCL INFO RAS client listening socket at ::1<28028>
llama-3-8b-node-0-0:188:585 [0] NCCL INFO Bootstrap timings total 8.128340 (create 0.000044, send 0.000162, recv 1.970281, ring 0.000162, delay 0.000000)
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/amazon/ofi-nccl/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
llama-3-8b-node-0-0:188:585 [0] NCCL INFO Setting affinity for GPU 0 to 0-23,48-71
llama-3-8b-node-0-0:188:585 [0] NCCL INFO comm 0x556d504b7460 rank 0 nRanks 4 nNodes 4 localRanks 1 localRank 0 MNNVL 0
llama-3-8b-node-0-0:188:585 [0] NCCL INFO Channel 00/02 : 0 1 2 3
llama-3-8b-node-0-0:188:585 [0] NCCL INFO Channel 01/02 : 0 1 2 3
llama-3-8b-node-0-0:188:585 [0] NCCL INFO Trees [0] 2/-1/-1->0->-1 [1] -1/-1/-1->0->1
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NCCL_BUFFSIZE set by environment to 8388608.
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NCCL_P2P_NET_CHUNKSIZE set by environment to 524288.
llama-3-8b-node-0-0:188:585 [0] NCCL INFO P2P Chunksize set to 524288
llama-3-8b-node-0-0:188:585 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
llama-3-8b-node-0-0:188:585 [0] NCCL INFO Check P2P Type isAllDirectP2p 0 directMode 0
llama-3-8b-node-0-0:188:655 [0] NCCL INFO [Proxy Service] Device 0 CPU core 18
llama-3-8b-node-0-0:188:656 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 65
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NCCL_PROTO set by environment to simple
llama-3-8b-node-0-0:188:585 [0] NCCL INFO Enabled NCCL Func/Proto/Algo Matrix:
     Function |       LL     LL128    Simple   |          Tree           Ring  CollNetDirect   CollNetChain           NVLS       NVLSTree            PAT  
    Broadcast |        0         0         1   |             1              1              1              1              1              1              1  
       Reduce |        0         0         1   |             1              1              1              1              1              1              1  
    AllGather |        0         0         1   |             1              1              1              1              1              1              1  
ReduceScatter |        0         0         1   |             1              1              1              1              1              1              1  
    AllReduce |        0         0         1   |             1              1              1              1              1              1              1  

llama-3-8b-node-0-0:188:585 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
llama-3-8b-node-0-0:188:585 [0] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
llama-3-8b-node-0-0:188:585 [0] NCCL INFO CC Off, workFifoBytes 1048576
llama-3-8b-node-0-0:188:585 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net.so
llama-3-8b-node-0-0:188:585 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v4 symbol.
llama-3-8b-node-0-0:188:585 [0] NCCL INFO TUNER/Plugin: Using tuner plugin nccl_ofi_tuner
llama-3-8b-node-0-0:188:585 [0] NCCL INFO NET/OFI NCCL_OFI_TUNER is not available for platform : p4d.24xlarge, Fall back to NCCL's tuner
llama-3-8b-node-0-0:188:585 [0] NCCL INFO ncclCommInitRankConfig comm 0x556d504b7460 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 101d0 commId 0xb079519ed44b724 - Init COMPLETE
llama-3-8b-node-0-0:188:585 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 8.31 (kernels 0.15, alloc 0.01, bootstrap 8.13, allgathers 0.00, topo 0.01, graphs 0.00, connections 0.00, rest 0.00)
The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
max_steps is given, it will override any value given in num_train_epochs
Using auto half precision backend
Gradient accumulation steps mismatch: GradientAccumulationPlugin has 1, DeepSpeed config has 4. Using DeepSpeed's value.
Detected ZeRO Offload and non-DeepSpeed optimizers: This combination should work as long as the custom optimizer has both CPU and GPU implementation (except LAMB)
[rank0]:W1231 01:46:57.058000 188 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank0]:W1231 01:46:57.058000 188 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1
llama-3-8b-node-0-0:188:188 [0] NCCL INFO Comm config Blocking set to 1
llama-3-8b-node-0-0:188:706 [0] NCCL INFO Assigned NET plugin Libfabric to comm
llama-3-8b-node-0-0:188:706 [0] NCCL INFO Using network Libfabric
llama-3-8b-node-0-0:188:706 [0] NCCL INFO DMA-BUF is available on GPU device 0
llama-3-8b-node-0-0:188:706 [0] NCCL INFO ncclCommSplit comm 0x556d50e02a40 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 101d0 parent 0x556d504b7460 splitCount 1 color 2003953581 key 0- Init START
llama-3-8b-node-0-0:188:706 [0] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/amazon/ofi-nccl/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
llama-3-8b-node-0-0:188:706 [0] NCCL INFO Setting affinity for GPU 0 to 0-23,48-71
llama-3-8b-node-0-0:188:706 [0] NCCL INFO comm 0x556d50e02a40 rank 0 nRanks 4 nNodes 4 localRanks 1 localRank 0 MNNVL 0
llama-3-8b-node-0-0:188:706 [0] NCCL INFO Channel 00/02 : 0 1 2 3
llama-3-8b-node-0-0:188:706 [0] NCCL INFO Channel 01/02 : 0 1 2 3
llama-3-8b-node-0-0:188:706 [0] NCCL INFO Trees [0] 2/-1/-1->0->-1 [1] -1/-1/-1->0->1
llama-3-8b-node-0-0:188:706 [0] NCCL INFO P2P Chunksize set to 524288
llama-3-8b-node-0-0:188:706 [0] NCCL INFO Check P2P Type isAllDirectP2p 0 directMode 0
llama-3-8b-node-0-0:188:707 [0] NCCL INFO [Proxy Service] Device 0 CPU core 48
llama-3-8b-node-0-0:188:708 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 21
llama-3-8b-node-0-0:188:706 [0] NCCL INFO NCCL_PROTO set by environment to simple
llama-3-8b-node-0-0:188:706 [0] NCCL INFO Enabled NCCL Func/Proto/Algo Matrix:
     Function |       LL     LL128    Simple   |          Tree           Ring  CollNetDirect   CollNetChain           NVLS       NVLSTree            PAT  
    Broadcast |        0         0         1   |             1              1              1              1              1              1              1  
       Reduce |        0         0         1   |             1              1              1              1              1              1              1  
    AllGather |        0         0         1   |             1              1              1              1              1              1              1  
ReduceScatter |        0         0         1   |             1              1              1              1              1              1              1  
    AllReduce |        0         0         1   |             1              1              1              1              1              1              1  

llama-3-8b-node-0-0:188:706 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
llama-3-8b-node-0-0:188:706 [0] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
llama-3-8b-node-0-0:188:706 [0] NCCL INFO CC Off, workFifoBytes 1048576
llama-3-8b-node-0-0:188:706 [0] NCCL INFO NET/OFI NCCL_OFI_TUNER is not available for platform : p4d.24xlarge, Fall back to NCCL's tuner
llama-3-8b-node-0-0:188:706 [0] NCCL INFO ncclCommSplit comm 0x556d50e02a40 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 101d0 parent 0x556d504b7460 splitCount 1 color 2003953581 key 0 - Init COMPLETE
llama-3-8b-node-0-0:188:706 [0] NCCL INFO Init timings - ncclCommSplit: rank 0 nranks 4 total 2.79 (kernels 0.00, alloc 0.00, bootstrap 0.00, allgathers 0.02, topo 0.01, graphs 0.00, connections 0.00, rest 2.75)
llama-3-8b-node-0-0:188:710 [0] NCCL INFO [Proxy Progress] Device 0 CPU core 56
llama-3-8b-node-0-0:188:709 [0] NCCL INFO Channel 00/0 : 3[0] -> 0[0] [receive] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:709 [0] NCCL INFO Channel 01/0 : 3[0] -> 0[0] [receive] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:709 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[0] [send] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:709 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[0] [send] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:709 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 0
Stage 3 initialize beginning
MA 14.96 GB         Max_MA 14.96 GB         CA 15.08 GB         Max_CA 15 GB 
CPU Virtual Memory:  used = 52.66 GB, percent = 4.7%
DeepSpeedZeRoOffload initialize [begin]
MA 14.96 GB         Max_MA 14.96 GB         CA 15.08 GB         Max_CA 15 GB 
CPU Virtual Memory:  used = 53.11 GB, percent = 4.7%
llama-3-8b-node-0-0:188:712 [0] NCCL INFO [Proxy Progress] Device 0 CPU core 67
llama-3-8b-node-0-0:188:711 [0] NCCL INFO Channel 00/0 : 3[0] -> 0[0] [receive] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:711 [0] NCCL INFO Channel 01/0 : 3[0] -> 0[0] [receive] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:711 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[0] [send] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:711 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[0] [send] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:711 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 0
Parameter Offload - Persistent parameters statistics: param_count = 65, numel = 266240
DeepSpeedZeRoOffload initialize [end]
MA 0.0 GB         Max_MA 14.96 GB         CA 15.08 GB         Max_CA 15 GB 
CPU Virtual Memory:  used = 69.59 GB, percent = 6.2%
Before creating fp16 partitions
MA 0.0 GB         Max_MA 0.0 GB         CA 15.08 GB         Max_CA 15 GB 
CPU Virtual Memory:  used = 69.29 GB, percent = 6.2%
llama-3-8b-node-0-0:188:760 [0] NCCL INFO Channel 00/0 : 2[0] -> 0[0] [receive] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:760 [0] NCCL INFO Channel 00/0 : 0[0] -> 2[0] [send] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:760 [0] NCCL INFO Channel 01/0 : 1[0] -> 0[0] [receive] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:760 [0] NCCL INFO Connected all trees
After creating fp16 partitions: 3
MA 0.0 GB         Max_MA 0.0 GB         CA 15.08 GB         Max_CA 15 GB 
CPU Virtual Memory:  used = 113.11 GB, percent = 10.1%
Before creating fp32 partitions
MA 0.0 GB         Max_MA 0.0 GB         CA 15.08 GB         Max_CA 15 GB 
CPU Virtual Memory:  used = 111.26 GB, percent = 9.9%
After creating fp32 partitions
MA 0.0 GB         Max_MA 0.0 GB         CA 15.08 GB         Max_CA 15 GB 
CPU Virtual Memory:  used = 116.03 GB, percent = 10.3%
Before initializing optimizer states
MA 0.0 GB         Max_MA 0.0 GB         CA 15.08 GB         Max_CA 15 GB 
CPU Virtual Memory:  used = 136.5 GB, percent = 12.2%
After initializing optimizer states
MA 0.0 GB         Max_MA 0.0 GB         CA 15.08 GB         Max_CA 15 GB 
CPU Virtual Memory:  used = 155.25 GB, percent = 13.8%
llama-3-8b-node-0-0:188:761 [0] NCCL INFO Channel 00/0 : 1[0] -> 0[0] [receive] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:761 [0] NCCL INFO Channel 00/0 : 0[0] -> 3[0] [send] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:761 [0] NCCL INFO Channel 01/0 : 0[0] -> 3[0] [send] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:761 [0] NCCL INFO Channel 01/0 : 2[0] -> 0[0] [receive] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:761 [0] NCCL INFO Channel 01/0 : 0[0] -> 2[0] [send] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:761 [0] NCCL INFO Connected binomial trees
After initializing ZeRO optimizer
MA 0.03 GB         Max_MA 1.99 GB         CA 15.08 GB         Max_CA 15 GB 
CPU Virtual Memory:  used = 172.96 GB, percent = 15.4%
***** Running training *****
  Num examples = 36,718
  Num Epochs = 1
  Instantaneous batch size per device = 4
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 4
  Total optimization steps = 50
  Number of trainable parameters = 8,030,261,248
llama-3-8b-node-0-0:188:764 [0] NCCL INFO Channel 00/0 : 1[0] -> 0[0] [receive] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:764 [0] NCCL INFO Channel 01/0 : 1[0] -> 0[0] [receive] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:764 [0] NCCL INFO Channel 00/0 : 0[0] -> 3[0] [send] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:764 [0] NCCL INFO Channel 01/0 : 0[0] -> 3[0] [send] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:764 [0] NCCL INFO Channel 00/0 : 2[0] -> 0[0] [receive] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:764 [0] NCCL INFO Channel 01/0 : 2[0] -> 0[0] [receive] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:764 [0] NCCL INFO Channel 00/0 : 0[0] -> 2[0] [send] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:764 [0] NCCL INFO Channel 01/0 : 0[0] -> 2[0] [send] via NET/Libfabric/0/GDRDMA
llama-3-8b-node-0-0:188:764 [0] NCCL INFO Connected binomial trees
llama-3-8b-node-0-0:188:765 [0] NCCL INFO Connected all trees
```
* 3[0] -> ê¸€ë¡œë²Œ ë­í¬ 3 / ë¡œì»¬ ë­í¬ 0  

#### 2. ì„±ëŠ¥ ì°¨ì´ (Bottleneck) ###
* NVLink ì†ë„: ìµœì‹  GPU(A100/H100/GB200) ê¸°ì¤€ ë…¸ë“œ ë‚´ë¶€ í†µì‹ ì€ ë³´í†µ 600 GB/s [NVLink 3.0] ~ 1,800 GB/s [NVLink 5.0]
* ë„¤íŠ¸ì›Œí¬(EFA) ì†ë„: EFA ëŠ” 100Gbps ~ 400Gbps (ì•½ 12.5GB/s ~ 50GB/s) ìˆ˜ì¤€ ì œê³µ.

#### 3. ê¸°ìˆ ì  ì˜ˆì™¸ (Pod Affinity & Shared Memory) ####
hostNetwork: trueë¥¼ ì‚¬ìš©í•˜ê³  IPC ì„¤ì •ì„ ì •êµí•˜ê²Œ í•˜ë©´ íŒŒë“œê°€ ë‹¬ë¼ë„ NVLinkë¥¼ ì“¸ ìˆ˜ëŠ” ìˆì§€ë§Œ, ì„¤ì •ì´ ë§¤ìš° ê¹Œë‹¤ë¡­ê³  ë³´ì•ˆìƒ ê¶Œì¥ë˜ì§€ ì•ŠëŠ”ë‹¤.


### cf. GPUë³„ ê°œë³„ Pod ì„¤ì • ###

ë§Œì•½, ìš´ì˜ìƒ ê°œë³„ GPU ë³„ë¡œ í•˜ë‚˜ì˜ Pod ë¥¼ í• ë‹¹í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ì™€ ê°™ì€ ì„¤ì •ìœ¼ë¡œ ê°€ëŠ¥í•˜ë‹¤. í•˜ì§€ë§Œ ì´ëŠ” ì„±ëŠ¥ì„ ëŒ€ê°€ë¡œ ê´€ë¦¬ í¸ì˜ì„±ì„ ì–»ëŠ” ì„ íƒìœ¼ë¡œ ê¶Œì¥í•˜ì§„ ì•ŠëŠ”ë‹¤. 
ì•„ë˜ ì˜ˆì‹œì—ì„œëŠ” 16ê°œì˜ ë…¸ë“œ(Pod)ë¥¼ ë¶„ì‚° í›ˆë ¨ì— ì‚¬ìš©í•˜ê³  ìˆëŠ”ë° ë…¸ë“œ(Pod)ë‹¹ 1ê°œì˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ë„ìš°ê³  ìˆìœ¼ë©°, íŒŒë“œë‹¹ ë¦¬ì†ŒìŠ¤ëŠ” 1 GPU / 1 EFA ì¸í„°í˜ì´ìŠ¤ë¥¼ í• ë‹¹í•˜ê³  ìˆë‹¤.
ë…¸ë“œ í• ë‹¹ì„ ë‹´ë‹¹í•˜ëŠ” ì¹´íœí„°ëŠ” GPUë¥¼ 8ì¥ íƒ‘ì¬í•˜ê³  ìˆëŠ” p4d.48xlarge ì™€ ê°™ì€ ì¸ìŠ¤í„´ìŠ¤ë¥¼ 2ëŒ€ ë„ìš°ê±°ë‚˜ GPU 4ì¥ì„ ê°€ì§„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ 4 ëŒ€ ë„ìš°ê±°ë‚˜ ì•„ë‹ˆë©´ GPU 1 ì¥ì„ ê°€ì§„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ 16ëŒ€ ë„ìš¸ ìˆ˜ë„ ìˆë‹¤.  
```
trainer:
    numNodes: 16                               # Pod(ë…¸ë“œ ë‹¨ìœ„)ë¥¼ 16ê°œ í• ë‹¹
    numProcPerNode: 1                          # Pod ë‚´ë¶€ì—ì„œ í”„ë¡œì„¸ìŠ¤ëŠ” 1ê°œë§Œ ì‹¤í–‰  
    image: ...                                 # Pod ì˜ ë¦¬ì†ŒìŠ¤ limit ì„¤ì •ì´ nvidia.com: "1" ì´ë¯€ë¡œ 1 ì´ìƒì˜ ê°’ì„ ì£¼ë©´ ì—ëŸ¬ ë°œìƒ.

    command:
        # ... (ì¤‘ëµ) ...
        torchrun \
          --nnodes=16 \                        # ì „ì²´ ë…¸ë“œ ìˆ˜ë¥¼ 16ìœ¼ë¡œ ëª…ì‹œ (ìƒëµê°€ëŠ¥)
          --nproc_per_node=1 \                 # Podë‹¹ 1ê°œ í”„ë¡œì„¸ìŠ¤ë§Œ ìƒì„± ëª…ì‹œ (ìƒëµê°€ëŠ¥)
          --rdzv_id=llama-3-8b-job \
          --rdzv_backend=c10d \
          --rdzv_endpoint=${PET_MASTER_ADDR}:${PET_MASTER_PORT} \
          llama-3-8b.py 

    resourcesPerNode:
      limits:
        nvidia.com: "1"                        # Pod GPUë¥¼ 1ê°œë¡œ ì œí•œ
        vpc.amazonaws.com: "1"                 # (EFA ì‚¬ìš© ì‹œ) 1ê°œ í• ë‹¹
```


